{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1cDcKRZwXCL"
   },
   "source": [
    "# Key-Value Attention Mechanism Homework on Keras: Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
    "\n",
    "In this homework, you will create an MT model with key-value attention mechnism that coverts names of constituency MP candidates in the 2019 Thai general election from Thai script to Roman(Latin) script. E.g. นิยม-->niyom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6024,
     "status": "ok",
     "timestamp": 1680718678537,
     "user": {
      "displayName": "Paisit Khanarsa",
      "userId": "13279666281938719332"
     },
     "user_tz": -420
    },
    "id": "Oy6QYsP4wa-k",
    "outputId": "8ac7d294-ec86-484c-d1cb-af31f6665b9f"
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
    "# try:\n",
    "#   # %tensorflow_version only exists in Colab.\n",
    "#   %tensorflow_version 2.x\n",
    "# except Exception:\n",
    "#   pass\n",
    "\n",
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# from matplotlib import font_manager\n",
    "# mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
    "# mpl.rc('font', family='TH Sarabun New')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRdbTrQJwXCR"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sq20keO6wXCh"
   },
   "source": [
    "## Load Dataset\n",
    "We have generated a toy dataset using names of constituency MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/dataset_diagram.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78675,
     "status": "ok",
     "timestamp": 1680719078872,
     "user": {
      "displayName": "Paisit Khanarsa",
      "userId": "13279666281938719332"
     },
     "user_tz": -420
    },
    "id": "B8ILK0shprTa",
    "outputId": "55715c6f-dfe1-4bf5-ad12-a021e5f8018a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1680719079637,
     "user": {
      "displayName": "Paisit Khanarsa",
      "userId": "13279666281938719332"
     },
     "user_tz": -420
    },
    "id": "ecQgM1JRp-7B",
    "outputId": "ed45f3dc-5bbd-4b3b-f968-e0cceb92e171"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.copy(\"/content/drive/MyDrive/FRA 501 IntroNLP&DL/Dataset/mp_name_th_en.csv\", \"/content/mp_name_th_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTQk8W4OwXCk"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# with open('Dataset/mp_name_th_en.csv') as csvfile:\n",
    "with open('Dataset/mp_name_th_en.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    name_th = []\n",
    "    name_en = []\n",
    "    for row in readCSV:\n",
    "        name_th.append(row[0])\n",
    "        name_en.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1680719134852,
     "user": {
      "displayName": "Paisit Khanarsa",
      "userId": "13279666281938719332"
     },
     "user_tz": -420
    },
    "id": "lVNHVM_FwXCs",
    "outputId": "1b5c8a4d-5d04-4266-e734-5e199bedaf05"
   },
   "outputs": [],
   "source": [
    "for th, en in zip(name_th[:10],name_en[:10]):\n",
    "    print(th,en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heMTiM7qwXC2"
   },
   "source": [
    "## Task1: Preprocess dataset for Keras\n",
    "* 2 dictionaries for indexing (1 for input and another for output) OK!\n",
    "* DON'T FORGET TO INCLUDE special token for padding OK!\n",
    "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output) OK!\n",
    "* Be mindful of your pad_sequences \"padding\" hyperparameter. Choose wisely (post-padding vs pre-padding) OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_O5YhjntwXC4"
   },
   "outputs": [],
   "source": [
    "#FILL YOUR CODE HERE\n",
    "print(\"th : {:d} | en : {:d}\".format(len(name_th),len(name_en)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda, Reshape, SimpleRNN\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [[1], [2, 3], [4, 5, 6]]\n",
    "b = pad_sequences(sequence, padding='pre')\n",
    "a = pad_sequences(sequence, padding='post')\n",
    "print(b)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name_th[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars = list(set(''.join(name_th)))\n",
    "output_chars = list(set(''.join(name_en)))\n",
    "# +1 for padding +1 for the end of word\n",
    "data_size, vocab_size = len(name_th), len(input_chars)+2 \n",
    "output_vocab_size = len(output_chars)+2\n",
    "\n",
    "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
    "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
    "maxlen_th = len( max(name_th, key=len)) #max input length\n",
    "print(\"Max input length:\", maxlen_th)\n",
    "maxlen_en = len( max(name_en, key=len)) #max input length\n",
    "print(\"Max output length:\", maxlen_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_chars= sorted(input_chars)\n",
    "sorted_output_chars= sorted(output_chars)\n",
    "sorted_chars.insert(0,\"<PAD>\") #PADDING for input\n",
    "sorted_output_chars.insert(0,\"<PAD>\") #PADDING for output\n",
    "sorted_chars.insert(1,\"</S>\") #the end of word for input\n",
    "sorted_output_chars.insert(1,\"</S>\") #the end of word for output\n",
    "#Input\n",
    "char_to_ix = { ch:i for i,ch in enumerate(sorted_chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted_chars) } #reverse dictionary\n",
    "#Output\n",
    "output_char_to_ix = { ch:i for i,ch in enumerate(sorted_output_chars) }\n",
    "ix_to_output_char = { i:ch for i,ch in enumerate(sorted_output_chars) } #reverse dictionary\n",
    "\n",
    "print(ix_to_char)\n",
    "print(ix_to_output_char)\n",
    "print(\"len(input) : %d | len(output) %d\" % (len(ix_to_char),len(ix_to_output_char)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=10887  # #sample\n",
    "Tx=maxlen_th # size of input = 20\n",
    "Ty=maxlen_en+1 # size of output = 19\n",
    "print(Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for line in name_th:\n",
    "    temp=[]\n",
    "    for char in line:\n",
    "        temp.append(char_to_ix[char])\n",
    "    temp.append(char_to_ix[\"</S>\"])\n",
    "    X.append(temp)\n",
    "Y = []\n",
    "for line in name_en:\n",
    "    temp=[]\n",
    "    for char in line:\n",
    "        temp.append(output_char_to_ix[char])\n",
    "    temp.append(char_to_ix[\"</S>\"])\n",
    "    Y.append(temp)    \n",
    "\n",
    "print(len(Y),output_vocab_size)\n",
    "print(\"Example X :\"+str(X))\n",
    "print(\"Example Y :\"+str(Y))\n",
    "\n",
    "X = pad_sequences(X,maxlen=maxlen_th,padding = 'pre')\n",
    "Y = pad_sequences(Y,maxlen=Ty,padding = 'pre')\n",
    "\n",
    "X= to_categorical(X,vocab_size)\n",
    "X=X.reshape(data_size,maxlen_th ,vocab_size)\n",
    "\n",
    "Y= to_categorical(Y,output_vocab_size)\n",
    "Y=Y.reshape(data_size,Ty ,output_vocab_size)\n",
    "print(\"X : %s | Y : %s\" % (str(X.shape),str(Y.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0].shape)\n",
    "print(Y[0].shape)\n",
    "print(X[1].shape)\n",
    "print(Y[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNqqnkVSwXC-"
   },
   "source": [
    "# Attention Mechanism\n",
    "## Task 2: Code your own (key-value) attention mechnism\n",
    "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
    "* Define global variables\n",
    "* fill code for one_step_attention function\n",
    "* Hint: use keras.layers.Lambda \n",
    "* Hint: you will probably need more hidden dimmensions than what you've seen in the demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSdFcuGuwXDB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow import split\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BS3Ziti1wXDH"
   },
   "outputs": [],
   "source": [
    "#These are global variables (shared layers)\n",
    "## Fill your code here\n",
    "## you are allowed to use code in the demo as your template. \n",
    "\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "\n",
    "#Key-values (Hint)\n",
    "splitter = Lambda(lambda x:split(x, num_or_size_splits=2,axis=2)) #ได้ key กับ value\n",
    "\n",
    "#Attention function###\n",
    "fattn_1 = Dense(128, activation = \"tanh\")\n",
    "fattn_2 = Dense(1, activation = \"relu\")\n",
    "\n",
    "#Attention function###\n",
    "###\n",
    "activator = Activation(softMaxAxis1, name='attention_scores') \n",
    "dotor = Dot(axes = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecNci8x5wXDN"
   },
   "outputs": [],
   "source": [
    "def one_step_attention(hidden, s_prev): # (hidden,vecter)\n",
    "\n",
    "    #Fill code here\n",
    "    key, value = splitter(hidden)\n",
    "\n",
    "    #return None # return whatever you need to complete this homework \n",
    "    s_prev = repeator(s_prev)\n",
    "    concat = concatenator([key,s_prev])\n",
    "    # attention function\n",
    "    e = fattn_1(concat)\n",
    "    energies =fattn_2(e)\n",
    "    # calculate attention_scores (softmax)\n",
    "    attention_scores = activator(energies)\n",
    "    #calculate a context vector\n",
    "    context = dotor([attention_scores,value])\n",
    "\n",
    "    return context,attention_scores,energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bgSCY3NwXDU"
   },
   "source": [
    "## Task3: Create and train your encoder/decoder model here\n",
    "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_h = 64 #hidden dimensions for encoder \n",
    "n_s = 128 #hidden dimensions for decoder\n",
    "encoder_LSTM =  Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))\n",
    "decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n",
    "output_layer = Dense(output_vocab_size, activation=\"softmax\") #softmax output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CVrgh9nwXDV"
   },
   "outputs": [],
   "source": [
    "#FILL CODE HERE :Hint --> heatmap in CNN + GradCAM\n",
    "\n",
    "def model(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n",
    "\n",
    "    # Define the input of your model\n",
    "    X = Input(shape=(Tx, vocab_size))\n",
    "    # Define hidden state and cell state for decoder_LSTM_Cell\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    # print(type(s))\n",
    "    # print(type(c))\n",
    "    # Initialize empty list of outputs\n",
    "    outputs = list()\n",
    "\n",
    "    #Encoder Bi-LSTM\n",
    "    # h = BidirectionaM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))(X)\n",
    "    h = encoder_LSTM(X)\n",
    "    #Iterate for Ty steps (Decoding)\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
    "        context,attention_scores,energies = one_step_attention(h, s)\n",
    "       \n",
    "        # Feed the context vector to the decoder LSTM cell\n",
    "        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n",
    "           \n",
    "        # Pass the decoder hidden output to the output layer (softmax)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Append an output list with the current output\n",
    "        outputs.append(out)\n",
    "    \n",
    "    #Create model instance\n",
    "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def inference_encoder(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n",
    "    X = Input(shape=(Tx, vocab_size))\n",
    "\n",
    "    h = encoder_LSTM(X)\n",
    "\n",
    "    model_inference_encoder = Model(inputs=[X],outputs=h)\n",
    "\n",
    "    return model_inference_encoder\n",
    "\n",
    "def inference_decoder(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    h = Input(shape=(Tx,n_h*2), name='h')\n",
    "    s = s0\n",
    "    c = c0\n",
    "\n",
    "    context, attention_scores, energies = one_step_attention(h, s)\n",
    "\n",
    "    s, _, c = decoder_LSTM_cell(context, initial_state=[s, c])\n",
    "\n",
    "    out = output_layer(s)\n",
    "\n",
    "    model_inference_encoder = Model(inputs=[h, s0, c0], outputs=[out, s, c, attention_scores, energies])\n",
    "\n",
    "    return model_inference_encoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XptuOQj-wXDb"
   },
   "outputs": [],
   "source": [
    "# FIT YOUR MODEL HERE\n",
    "model = model(Tx, Ty, n_h, n_s, vocab_size, output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Y.swapaxes(0,1))\n",
    "opt=Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy')\n",
    "model.fit([X, s0, c0], outputs, epochs=15, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C2RET9GwXDh"
   },
   "source": [
    "# Thai-Script to Roman-Script Translation\n",
    "* Task 4: Test your model on 5 examples of your choice including your name! \n",
    "* Task 5: Show your visualization of attention scores on one of your example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gON7T2xVwXDk"
   },
   "outputs": [],
   "source": [
    "#task 4\n",
    "#fill your code here\n",
    "def prep_input(input_list):\n",
    "    X = []\n",
    "    for line in input_list:\n",
    "        temp=[]\n",
    "        for char in line:\n",
    "            temp.append(char_to_ix[char])\n",
    "        X.append(temp)\n",
    "    X = pad_sequences(X,maxlen=maxlen_th)\n",
    "    X= to_categorical(X,vocab_size)\n",
    "    X=X.reshape(len(input_list),maxlen_th ,vocab_size)\n",
    "    \n",
    "    return X\n",
    "\n",
    "EXAMPLES = ['สมชาย','สมศักดิ์','อดัม','ก้องภพ','ธนัท','ใจดี']\n",
    "Sample = EXAMPLES\n",
    "s0 = np.zeros((len(EXAMPLES), n_s))\n",
    "c0 = np.zeros((len(EXAMPLES), n_s))\n",
    "EXAMPLES = prep_input(EXAMPLES)\n",
    "\n",
    "prediction = model.predict([EXAMPLES , s0, c0])\n",
    "# print(type(prediction))\n",
    "# print(len(prediction))\n",
    "# print(prediction)\n",
    "prediction = np.swapaxes(prediction,0,1)\n",
    "prediction = np.argmax(prediction, axis = -1)\n",
    "# print(prediction)\n",
    "\n",
    "for j in range(len(prediction)):\n",
    "    output = \"\".join([ix_to_output_char[int(i)] for i in prediction[j]])\n",
    "    print(output)\n",
    "\n",
    "for j in range(len(prediction)):\n",
    "    output = \"\".join([ix_to_output_char[int(i)] for i in prediction[j]])\n",
    "    output = output.replace('<PAD>','')\n",
    "    output = output.replace('</S>','')\n",
    "    print(Sample[j],output)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9-mxbsKwXDp"
   },
   "source": [
    "### Plot the attention map\n",
    "* If you need to install thai font: sudo apt install xfonts-thai\n",
    "* this is what your visualization might look like:\n",
    "--> https://drive.google.com/file/d/168J5SPSf4NNKj718wWUEDpUbh8QYZKux/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit attention_scores in one step attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4lhl4Vsz6Y8"
   },
   "outputs": [],
   "source": [
    "EXAMPLES = ['สมชาย','สมศักดิ์','อดัม','ก้องภพ','ธนัท','ใจดี']\n",
    "temp = EXAMPLES\n",
    "inferEncoder_model = inference_encoder(Tx, Ty, n_h, n_s, vocab_size, output_vocab_size)\n",
    "inferDecoder_model = inference_decoder(Tx, Ty, n_h, n_s, vocab_size, output_vocab_size)\n",
    "\n",
    "s0 = np.zeros((len(EXAMPLES), n_s))\n",
    "c0 = np.zeros((len(EXAMPLES), n_s))\n",
    "s = s0\n",
    "c = c0\n",
    "\n",
    "EXAMPLES = prep_input(EXAMPLES)\n",
    "h = inferEncoder_model.predict(EXAMPLES,verbose=0)\n",
    "\n",
    "Ty = 20\n",
    "score = []\n",
    "attention_list = []\n",
    "\n",
    "for t in range(Ty):\n",
    "    out,s,c,attention_scores,energies = inferDecoder_model.predict([h,s,c],verbose=0)\n",
    "    score.append(out)\n",
    "    # print(out)\n",
    "    print(attention_scores.shape)\n",
    "    print(\"attention_scores : \",attention_scores)\n",
    "    attention_list.append(attention_scores)\n",
    "    # array=np.array(out)\n",
    "    \n",
    "prediction = np.swapaxes(score,0,1)\n",
    "prediction = np.argmax(prediction, axis = -1)\n",
    "\n",
    "attention_list = np.array(attention_list)\n",
    "output_list=[]\n",
    "\n",
    "for j in range(len(prediction)):\n",
    "    a = [ix_to_output_char[int(i)] for i in prediction[j]]\n",
    "    output = \"\".join(a)\n",
    "    output_list.append([[temp[j]],a])\n",
    "    # output = output.replace('<PAD>','')\n",
    "    # output = output.replace('<END>','')\n",
    "    print(temp[j],output)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRL8hHaLwXDq"
   },
   "outputs": [],
   "source": [
    "#task 5\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family']='TH Sarabun New'  #you can change to other font that works for you\n",
    "#fill your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XT44RFuxqzBM"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"(number , Ty)\",prediction.shape)\n",
    "attention_list = np.swapaxes(attention_list,0,1)\n",
    "print(attention_list)\n",
    "print(\"(number Tx , Ty )\",attention_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_indices(word_list):\n",
    "    start_index = None\n",
    "    end_index = None\n",
    "    \n",
    "    for i in range(len(word_list)):\n",
    "        if word_list[i] != '<PAD>':\n",
    "            if start_index is None:\n",
    "                start_index = i\n",
    "            if word_list[i] == '<END>':\n",
    "                end_index = i\n",
    "                break\n",
    "    \n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fm.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
    "matplotlib.rc('font', family='TH Sarabun New')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotheat(output_list,atten):\n",
    "    fig, ax = plt.subplots(nrows = 6, figsize=(10,50))\n",
    "    for index,i in enumerate(output_list) :\n",
    "        word = i[0]\n",
    "        word_padded = ['<PAD>']*(Tx - len(word[0])) + list(word[0]) \n",
    "        start,end = get_word_indices(i[1])\n",
    "        att = atten[index]\n",
    "        a = att.reshape(20,20)\n",
    "        a = a[start:end,:]\n",
    "        print(a.shape)\n",
    "        out = list(filter((lambda x : x != \"<PAD>\" and x != \"<END>\" ),i[1]) )\n",
    "        print(out)\n",
    "        print(a)\n",
    "        sns.heatmap(a,xticklabels=word_padded, yticklabels=out, vmin=0, vmax=1 , ax=ax[index])\n",
    "        ax[index].set_title(word[0])\n",
    "        # break\n",
    "    plt.show()\n",
    "\n",
    "plotheat(output_list,attention_list)\n",
    "# print(output_list[0][1])\n",
    "# start,end = get_word_indices(output_list[0][1])\n",
    "# print(start,end)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
