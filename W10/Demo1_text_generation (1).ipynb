{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87UHAQkt5dIw"
      },
      "source": [
        "# Text Generation Demo on Keras: Date Generation (One-to-Many)\n",
        "\n",
        "In this demo, we will show you how to create a text generator using Keras. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. In this demo, we create a one-to-many RNN model for generating date in the following format: e.g. \"2002-03-11\".  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIz3jAIF5dI1"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import sys\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 1.x \n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.backend import argmax,one_hot\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Reshape, Input, Lambda\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf. __version__) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cweg2AkVkVJT",
        "outputId": "120b5d25-90eb-4a79-9e94-fee6a620ae9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULHSHW5X5dJE"
      },
      "source": [
        "## Generate Dataset\n",
        "We generate a toy dataset using datetime library.  The target output only comes in one format (iso format). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km8dKUXP5dJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ebdbc1-cb88-45b5-e448-116fffdac641"
      },
      "source": [
        "#Generating a toy dataset\n",
        "import datetime\n",
        "base = datetime.datetime.today()\n",
        "base = datetime.date(base.year, base.month, base.day)\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 1500)]\n",
        "data = [date.isoformat() for date in date_list] \n",
        "print(data[:5])\n",
        "maxlen=10 #all the seqeunces have 10 characters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2023-03-30', '2023-03-29', '2023-03-28', '2023-03-27', '2023-03-26']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKLIr4Od5dJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92301b9-6528-48fc-f498-13b04a82c9a1"
      },
      "source": [
        "chars = list(set(''.join(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d lines and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print(\"max length =\",maxlen)\n",
        "sorted_chars= sorted(chars)\n",
        "print(sorted_chars)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1500 lines and 11 unique characters in your data.\n",
            "max length = 10\n",
            "['-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO-IDo5A5dJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5df85f-8432-4b0a-850d-d265dee63c43"
      },
      "source": [
        "# In this demo, we will use \"<S>\" as a seed character to initiate the sequence\n",
        "sorted_chars.insert(0,\"<S>\") \n",
        "print(sorted_chars)\n",
        "vocab_size = len(sorted_chars)\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<S>', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPVwfBFe5dJj"
      },
      "source": [
        "Create a dictionary to map a character to an integer, and a reverse dictionary that does the opposite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qPAHf_P5dJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d17fcc-5603-4fac-917c-a776cdcdba94"
      },
      "source": [
        "char_to_ix = { ch:i for i,ch in enumerate(sorted_chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(sorted_chars) } #reverse dictionary\n",
        "print(char_to_ix)\n",
        "print(ix_to_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<S>': 0, '-': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
            "{0: '<S>', 1: '-', 2: '0', 3: '1', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRuFbBUx5dJr"
      },
      "source": [
        "# Preprocessing data for Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw-BupZv5dJt"
      },
      "source": [
        "#Preparing output data for the model\n",
        "Y = []\n",
        "for line in data:\n",
        "    temp=[]\n",
        "    for char in line:\n",
        "        temp.append(char_to_ix[char]) #character to index\n",
        "    Y.append(temp)\n",
        "pre_Y = Y    \n",
        "\n",
        "#Preparing input data for the model\n",
        "#The first element of the sequence is an initial seed\n",
        "#The rest is just like Y but shifted by one-time-step \n",
        "X = []\n",
        "for item in Y:\n",
        "    X.append([0]+item[:-1]) #Add initial seed <S> and shift X by one time step\n",
        "pre_X = X        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(pre_X).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TOWUWYvv1RU",
        "outputId": "b8c31df3-ab4b-4c83-a5e7-414a287e2b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_X[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M-gimQqtTB7",
        "outputId": "54b4503f-b523-4ee1-a55a-21e71848a01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 4, 2, 4, 5, 1, 2, 5, 1, 5],\n",
              " [0, 4, 2, 4, 5, 1, 2, 5, 1, 4],\n",
              " [0, 4, 2, 4, 5, 1, 2, 5, 1, 4],\n",
              " [0, 4, 2, 4, 5, 1, 2, 5, 1, 4],\n",
              " [0, 4, 2, 4, 5, 1, 2, 5, 1, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(pre_Y).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88t0cShAvv3k",
        "outputId": "40072cfd-4fc3-423c-a92f-ed4beee026d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_Y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGwyxkcWtUUr",
        "outputId": "9eef1281-2094-48bb-cd6b-1e06b11bf04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 2, 4, 5, 1, 2, 5, 1, 5, 2],\n",
              " [4, 2, 4, 5, 1, 2, 5, 1, 4, 11],\n",
              " [4, 2, 4, 5, 1, 2, 5, 1, 4, 10],\n",
              " [4, 2, 4, 5, 1, 2, 5, 1, 4, 9],\n",
              " [4, 2, 4, 5, 1, 2, 5, 1, 4, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing data for Keras    \n",
        "X= to_categorical(X,vocab_size) #one-hot\n",
        "Y= to_categorical(Y,vocab_size)\n",
        "X=X.reshape(data_size,maxlen ,vocab_size)\n",
        "Y=Y.reshape(data_size,maxlen ,vocab_size)\n",
        "Y= np.swapaxes(Y,0,1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dj5YG18v6n9",
        "outputId": "91cb2eda-6fbe-4045-ee1b-dc09d968e249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 10, 12) (10, 1500, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape,Y.shape) #--> (#sample,length of the sequence,#unique labels), (length of the sequence,#sample,#unique labels)\n",
        "print(X[:,0,:].shape,Y[0,:,:].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghy20mVVytnW",
        "outputId": "1aced91c-abc1-4e5b-971c-68a4f9d20117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 10, 12) (10, 1500, 12)\n",
            "(1500, 12) (1500, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwKOiX5B5dJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991fbf6f-46c1-45ef-eb9d-3960bf5b55f0"
      },
      "source": [
        "#Sample number 0, length of the sequence -- > 10 \n",
        "print(data[0])\n",
        "for t in range(10):\n",
        "    print(X[0,t,:])\n",
        "print()\n",
        "for t in range(10):\n",
        "    print(Y[t,0,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-30\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmXcPnNi5dJ9"
      },
      "source": [
        "# The model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q72wluQw5dJ9"
      },
      "source": [
        "#Shared layers (Global)\n",
        "n_a = 16 #number of hidden dimensions\n",
        "reshapor = Reshape((1,  vocab_size)) #Reshape the size of a tensor                         \n",
        "RNN_cell = SimpleRNN(n_a, return_state = True) #An RNN Cell       \n",
        "output_layer = Dense( vocab_size, activation='softmax')  #softmax output layer  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rm1Qds45dKF"
      },
      "source": [
        "def train_model(Tx, n_a, n_values):\n",
        "    \"\"\"\n",
        "    Implement the model for the training phase\n",
        "    \n",
        "    Arguments:\n",
        "    Tx -- length of the sequence \n",
        "    n_a -- the number of hidden dimensions used in our model\n",
        "    n_values -- number of unique labels in the data \n",
        "    \n",
        "    Returns:\n",
        "    model -- a keras model instance\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "      \n",
        "    # Define the input of your model\n",
        "    X = Input(shape=(Tx, n_values))  #--> (#sample,length of the sequence,#unique labels)\n",
        "    \n",
        "    # Define a0, initial hidden state for the RNN\n",
        "    a0 = Input(shape=(n_a,), name='a0')\n",
        "    a = a0\n",
        "    \n",
        "    # Create empty list to append an output from the model in each loop\n",
        "    outputs = list()\n",
        "    \n",
        "    # Loop  through the sequence of length Tx\n",
        "    for t in range(Tx):\n",
        "        # Select the \"t\"th time step vector from X.\n",
        "        x =  X[:,t,:] #--> shape(n_values)\n",
        "        # Reshape x to be (1, n_values)\n",
        "        x = reshapor(x) \n",
        "        # Update the hidden state of the RNN \n",
        "        a, _ = RNN_cell(x, initial_state=[a]) \n",
        "        # Pass the hidden vector to a softmax function\n",
        "        out = output_layer(a)\n",
        "        # Append an output list with the current output\n",
        "        outputs.append(out)\n",
        "        \n",
        "    # Create the model instance\n",
        "    model =  Model(inputs=[X,a0], outputs=outputs)    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maKBU9iN5dKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5e93ed-da36-40dd-b1a8-3f5720454e7c"
      },
      "source": [
        "model = train_model(Tx = maxlen, n_a = n_a, n_values = vocab_size)\n",
        "opt = Adam(lr=0.001) #optimizer\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 12)]     0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 12)          0           ['input_1[0][0]']                \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 1, 12)        0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem_1[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_5[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_6[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_7[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_8[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " a0 (InputLayer)                [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " simple_rnn (SimpleRNN)         [(None, 16),         464         ['reshape[0][0]',                \n",
            "                                 (None, 16)]                      'a0[0][0]',                     \n",
            "                                                                  'reshape[1][0]',                \n",
            "                                                                  'simple_rnn[0][0]',             \n",
            "                                                                  'reshape[2][0]',                \n",
            "                                                                  'simple_rnn[1][0]',             \n",
            "                                                                  'reshape[3][0]',                \n",
            "                                                                  'simple_rnn[2][0]',             \n",
            "                                                                  'reshape[4][0]',                \n",
            "                                                                  'simple_rnn[3][0]',             \n",
            "                                                                  'reshape[5][0]',                \n",
            "                                                                  'simple_rnn[4][0]',             \n",
            "                                                                  'reshape[6][0]',                \n",
            "                                                                  'simple_rnn[5][0]',             \n",
            "                                                                  'reshape[7][0]',                \n",
            "                                                                  'simple_rnn[6][0]',             \n",
            "                                                                  'reshape[8][0]',                \n",
            "                                                                  'simple_rnn[7][0]',             \n",
            "                                                                  'reshape[9][0]',                \n",
            "                                                                  'simple_rnn[8][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  (None, 12)          0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 12)           204         ['simple_rnn[0][0]',             \n",
            "                                                                  'simple_rnn[1][0]',             \n",
            "                                                                  'simple_rnn[2][0]',             \n",
            "                                                                  'simple_rnn[3][0]',             \n",
            "                                                                  'simple_rnn[4][0]',             \n",
            "                                                                  'simple_rnn[5][0]',             \n",
            "                                                                  'simple_rnn[6][0]',             \n",
            "                                                                  'simple_rnn[7][0]',             \n",
            "                                                                  'simple_rnn[8][0]',             \n",
            "                                                                  'simple_rnn[9][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 668\n",
            "Trainable params: 668\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZruJrru5dKT"
      },
      "source": [
        "### inference model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfhqNW3X5dKV"
      },
      "source": [
        "def inference_model(RNN_cell, output_layer, n_values = vocab_size , n_a = n_a, Ty = maxlen):\n",
        "    \"\"\"\n",
        "    Implement the model for inferencing/testing phase using the parameters learned from the previous steps\n",
        "    \n",
        "    Arguments:\n",
        "    RNN_cell -- the trained \"RNN_cell\" from train_model(), Keras layer object\n",
        "    output_layer -- the trained \"output_layer\" from train_model(), Keras layer object\n",
        "    n_values -- mumber of unique characters\n",
        "    n_a -- number of dimensions in RNN_Cell\n",
        "    Ty -- number of time steps to generate\n",
        "    \n",
        "    Returns:\n",
        "    inference_model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model\n",
        "    x0 = Input(shape=(1, n_values))\n",
        "    \n",
        "    # Define a0, initial hidden state for the decoder RNN\n",
        "    a0 = Input(shape=(n_a,), name='a0')\n",
        "    a = a0\n",
        "    x = x0\n",
        "\n",
        "    # Create an empty list of \"outputs\" to stored the predicted outputs\n",
        "    outputs = list()\n",
        "    \n",
        "    #Loop over Ty and generate a value at each time step\n",
        "    for t in range(Ty):\n",
        "        \n",
        "        # Perform one step of RNN_cell \n",
        "        a, _ = RNN_cell(x, initial_state=[a])\n",
        "        \n",
        "        # Apply Dense softmax layer to the hidden state output of the RNN_cell\n",
        "        out = output_layer(a)\n",
        "\n",
        "        # Append an output list with the current output\n",
        "        outputs.append(out)\n",
        "        \n",
        "        # Sample the new value to pass to the next time step\n",
        "        #tf.log because tf.multinomail wants unnormalized log-prob inputs\n",
        "        x  = Lambda(lambda x: one_hot(tf.random.categorical(tf.math.log(x), 1), num_classes=vocab_size))(out)\n",
        "        x = Reshape((1,vocab_size))(x)\n",
        "  \n",
        "    #Create the model instance\n",
        "    inference_model = Model(inputs=[x0,a0], outputs=outputs)\n",
        "    \n",
        "    return inference_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8pKC6oK5dKb"
      },
      "source": [
        "inference_model = inference_model(RNN_cell, output_layer, n_values = vocab_size, n_a = n_a, Ty = maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CGMaJi4h5dKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f1ee62-4ad7-4887-cbcc-9673e4c67cc9"
      },
      "source": [
        "x_initializer = np.zeros((1, 1, vocab_size))\n",
        "a_initializer = np.zeros((1, n_a))\n",
        "inference_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1, 12)]      0           []                               \n",
            "                                                                                                  \n",
            " a0 (InputLayer)                [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " simple_rnn (SimpleRNN)         [(None, 16),         464         ['input_2[0][0]',                \n",
            "                                 (None, 16)]                      'a0[0][0]',                     \n",
            "                                                                  'reshape_1[0][0]',              \n",
            "                                                                  'simple_rnn[10][0]',            \n",
            "                                                                  'reshape_2[0][0]',              \n",
            "                                                                  'simple_rnn[11][0]',            \n",
            "                                                                  'reshape_3[0][0]',              \n",
            "                                                                  'simple_rnn[12][0]',            \n",
            "                                                                  'reshape_4[0][0]',              \n",
            "                                                                  'simple_rnn[13][0]',            \n",
            "                                                                  'reshape_5[0][0]',              \n",
            "                                                                  'simple_rnn[14][0]',            \n",
            "                                                                  'reshape_6[0][0]',              \n",
            "                                                                  'simple_rnn[15][0]',            \n",
            "                                                                  'reshape_7[0][0]',              \n",
            "                                                                  'simple_rnn[16][0]',            \n",
            "                                                                  'reshape_8[0][0]',              \n",
            "                                                                  'simple_rnn[17][0]',            \n",
            "                                                                  'reshape_9[0][0]',              \n",
            "                                                                  'simple_rnn[18][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 12)           204         ['simple_rnn[10][0]',            \n",
            "                                                                  'simple_rnn[11][0]',            \n",
            "                                                                  'simple_rnn[12][0]',            \n",
            "                                                                  'simple_rnn[13][0]',            \n",
            "                                                                  'simple_rnn[14][0]',            \n",
            "                                                                  'simple_rnn[15][0]',            \n",
            "                                                                  'simple_rnn[16][0]',            \n",
            "                                                                  'simple_rnn[17][0]',            \n",
            "                                                                  'simple_rnn[18][0]',            \n",
            "                                                                  'simple_rnn[19][0]']            \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 12)        0           ['dense[10][0]']                 \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 12)        0           ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 12)        0           ['dense[11][0]']                 \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 12)        0           ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 12)        0           ['dense[12][0]']                 \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 1, 12)        0           ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 12)        0           ['dense[13][0]']                 \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 12)        0           ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 12)        0           ['dense[14][0]']                 \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 1, 12)        0           ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 12)        0           ['dense[15][0]']                 \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 12)        0           ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 12)        0           ['dense[16][0]']                 \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)            (None, 1, 12)        0           ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 12)        0           ['dense[17][0]']                 \n",
            "                                                                                                  \n",
            " reshape_8 (Reshape)            (None, 1, 12)        0           ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 12)        0           ['dense[18][0]']                 \n",
            "                                                                                                  \n",
            " reshape_9 (Reshape)            (None, 1, 12)        0           ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 668\n",
            "Trainable params: 668\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3vGypXs5dKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c10f57-83ec-468e-cc74-628eeea5082d"
      },
      "source": [
        "x_initializer[0][0][char_to_ix[\"<S>\"]] = 1 #initial seed\n",
        "print(np.argmax(x_initializer[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR4gTiH15dKp"
      },
      "source": [
        "def generate_date(inference_model, x_initializer = x_initializer, a_initializer = a_initializer):\n",
        "    \"\"\"\n",
        "    generate a date using the inference model.\n",
        "    \n",
        "    Arguments:\n",
        "    inference_model -- Keras model instance for inference/test time\n",
        "    x_initializer -- numpy array of shape (1, 1, 12), one-hot vector initializing the values generation\n",
        "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the RNN_cell\n",
        "    \n",
        "    Returns:\n",
        "    text -- a generated text string\n",
        "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
        "    \"\"\"\n",
        "    \n",
        "    #predict\n",
        "    pred = inference_model.predict([x_initializer,a_initializer])\n",
        "    #turn predictions into integers\n",
        "    indices = np.argmax(pred,axis=-1)\n",
        "    #intergers to text\n",
        "    text = \"\".join([ix_to_char[r[0]] for r in indices])\n",
        "    \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyPoqqCC5dKv"
      },
      "source": [
        "#Create a call back function\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    if(epoch%10==0):\n",
        "        print()\n",
        "        print('----- Generating text after Epoch: %d' % epoch)\n",
        "        for i in range(3):\n",
        "            text = generate_date(inference_model, x_initializer, a_initializer)\n",
        "            sys.stdout.write(text)\n",
        "            sys.stdout.flush()\n",
        "            print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4M8URGW5dK0"
      },
      "source": [
        "# Let's train the model and generate some text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I51dOIR15dK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a40bd72-85a2-4084-a496-6232985ed966"
      },
      "source": [
        "m = data_size\n",
        "a0 = np.zeros((m, n_a))\n",
        "model.fit([X, a0], list(Y),verbose=0 ,epochs=100,callbacks=[print_callback])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- Generating text after Epoch: 0\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "0000233-22\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "0020223020\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "0001016-24\n",
            "\n",
            "----- Generating text after Epoch: 10\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2020-01-10\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2029-02-09\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2020-02-19\n",
            "\n",
            "----- Generating text after Epoch: 20\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2020-01-29\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2020-01-10\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2020-01-26\n",
            "\n",
            "----- Generating text after Epoch: 30\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2029-03-11\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2020-02-06\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2020-01-21\n",
            "\n",
            "----- Generating text after Epoch: 40\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2020-03-20\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2020-03-14\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2029-03-11\n",
            "\n",
            "----- Generating text after Epoch: 50\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2020-03-14\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2020-00-24\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2020-03-24\n",
            "\n",
            "----- Generating text after Epoch: 60\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2020-03-21\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2020-03-22\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2020-03-21\n",
            "\n",
            "----- Generating text after Epoch: 70\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2022-08-21\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2022-00-14\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2022-03-22\n",
            "\n",
            "----- Generating text after Epoch: 80\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2020-08-22\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2029-07-23\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2020-01-26\n",
            "\n",
            "----- Generating text after Epoch: 90\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2020-03-28\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2020-08-28\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2029-09-29\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11e80c5eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhpse2Wl1-QR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}