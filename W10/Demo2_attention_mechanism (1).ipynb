{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB0ipHig9gOm"
      },
      "source": [
        "# Attention Mechanism Demo on Keras: Machine Translation Example (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this demo, we will show you how to create a machine translator using Keras. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. (Programming Assignment: Neural Machine Translation with Attention)    In this demo, we create a machine translator to translate dates in various formats  into dates in an ISO format. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_clL4w89gOt",
        "outputId": "89af5dcc-34a6-48d1-f0bb-c5b4382c670c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEyHEfFt9gO9"
      },
      "source": [
        "## Generate Dataset\n",
        "We generate a toy dataset using datetime library.  A target output only comes in one format (iso format), while there are three different date format for an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MWRgqvwY9gO_"
      },
      "outputs": [],
      "source": [
        "#Generating a toy dataset\n",
        "import datetime\n",
        "base = datetime.datetime.today()\n",
        "base = datetime.date(base.year, base.month, base.day)\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 15000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrNHzgFy9gPI",
        "outputId": "e6a35f39-347e-4462-f1cb-b17c979a72a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-27\n"
          ]
        }
      ],
      "source": [
        "target_date_list = [date.isoformat() for date in date_list] \n",
        "print(target_date_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GT7V4FJL9gPR"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from random import randint\n",
        "random.seed(42)\n",
        "input_date_list = list()\n",
        "for date in date_list:\n",
        "    random_num = randint(0, 2)\n",
        "    if random_num == 0:\n",
        "        input_date_list.append(date.strftime(\"%d/%m/%y\"))#\"11/03/02\"\n",
        "    elif random_num == 1:\n",
        "        input_date_list.append(date.strftime(\"%A %d %B %Y\")) #\"Monday 11 March 2002\"\n",
        "    elif random_num == 2: \n",
        "        input_date_list.append(date.strftime(\"%d %B %Y\")) #\"11 March 2002\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isfXKy2y9gPZ",
        "outputId": "3d89f5f9-5e4f-4ee9-ab11-a32d6c711659"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27 April 2023 2023-04-27\n",
            "26/04/23 2023-04-26\n",
            "25/04/23 2023-04-25\n",
            "24 April 2023 2023-04-24\n",
            "Sunday 23 April 2023 2023-04-23\n",
            "22/04/23 2023-04-22\n",
            "21/04/23 2023-04-21\n",
            "20/04/23 2023-04-20\n",
            "19 April 2023 2023-04-19\n",
            "18/04/23 2023-04-18\n"
          ]
        }
      ],
      "source": [
        "for input_sample, target_sample in zip(input_date_list[0:10],target_date_list[0:10]):\n",
        "    print(input_sample,target_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KndjKsS9gPg",
        "outputId": "e9ae3f66-8d05-44cd-c925-51999ed618ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 15000 lines and 42 unique characters in your input data.\n"
          ]
        }
      ],
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(input_date_list)))\n",
        "output_chars = list(set(''.join(target_date_list)))\n",
        "\n",
        "# +1 for padding\n",
        "data_size, vocab_size = len(input_date_list), len(input_chars)+1 \n",
        "output_vocab_size = len(output_chars)+1\n",
        "\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(input_date_list, key=len)) #max input length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K-0kaUH9gPn",
        "outputId": "e49f0186-7fdd-4f73-c631-edd3786b2de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max input length: 27\n"
          ]
        }
      ],
      "source": [
        "print(\"Max input length:\", maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCSo8cR29gPu",
        "outputId": "7bc98c52-e3a7-4264-f39e-79c9ce863337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '<PAD>', 1: ' ', 2: '/', 3: '0', 4: '1', 5: '2', 6: '3', 7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: 'A', 14: 'D', 15: 'F', 16: 'J', 17: 'M', 18: 'N', 19: 'O', 20: 'S', 21: 'T', 22: 'W', 23: 'a', 24: 'b', 25: 'c', 26: 'd', 27: 'e', 28: 'g', 29: 'h', 30: 'i', 31: 'l', 32: 'm', 33: 'n', 34: 'o', 35: 'p', 36: 'r', 37: 's', 38: 't', 39: 'u', 40: 'v', 41: 'y'}\n",
            "{0: '<PAD>', 1: '-', 2: '0', 3: '1', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9'}\n"
          ]
        }
      ],
      "source": [
        "sorted_chars= sorted(input_chars)\n",
        "sorted_output_chars= sorted(output_chars)\n",
        "sorted_chars.insert(0,\"<PAD>\") #PADDING for input\n",
        "sorted_output_chars.insert(0,\"<PAD>\") #PADDING for output\n",
        "#Input\n",
        "char_to_ix = { ch:i for i,ch in enumerate(sorted_chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(sorted_chars) } #reverse dictionary\n",
        "#Output\n",
        "output_char_to_ix = { ch:i for i,ch in enumerate(sorted_output_chars) }\n",
        "ix_to_output_char = { i:ch for i,ch in enumerate(sorted_output_chars) } #reverse dictionary\n",
        "\n",
        "print(ix_to_char)\n",
        "print(ix_to_output_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8Q0XsxhL9gP2"
      },
      "outputs": [],
      "source": [
        "m=15000  # #sample\n",
        "Tx=maxlen # size of input = 27\n",
        "Ty=10 # size of output = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvKOfVnc9gP-",
        "outputId": "1581e27e-5f01-4b69-972c-84d65540758e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15000 12\n",
            "(15000, 27, 42) (15000, 10, 12)\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "for line in input_date_list:\n",
        "    temp=[]\n",
        "    for char in line:\n",
        "        temp.append(char_to_ix[char])\n",
        "    X.append(temp)\n",
        "Y = []\n",
        "for line in target_date_list:\n",
        "    temp=[]\n",
        "    for char in line:\n",
        "        temp.append(output_char_to_ix[char])\n",
        "    Y.append(temp)    \n",
        "\n",
        "X = pad_sequences(X,maxlen=maxlen)\n",
        "# Y = pad_sequences(Y,maxlen=10)\n",
        "\n",
        "X= to_categorical(X,vocab_size)\n",
        "X=X.reshape(data_size,maxlen ,vocab_size)\n",
        "\n",
        "print(len(Y),output_vocab_size)\n",
        "Y= to_categorical(Y,output_vocab_size)\n",
        "Y=Y.reshape(data_size,10 ,output_vocab_size)\n",
        "print(X.shape,Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFYhwzdj9gQG"
      },
      "source": [
        "# Attention Mechanism\n",
        "--> https://drive.google.com/file/d/1xY2_yGARtR8MDw231j7OmH-zCB4XiOkl/view?usp=share_link "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "76X7VMpD9gQI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.activations import softmax\n",
        "def softMaxAxis1(x):\n",
        "    return softmax(x,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "FhngrOGI9gQO"
      },
      "outputs": [],
      "source": [
        "#These are global variables (shared layers)\n",
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "#Attention function###\n",
        "fattn_1 = Dense(10, activation = \"tanh\")\n",
        "fattn_2 = Dense(1, activation = \"relu\")\n",
        "###\n",
        "activator = Activation(softMaxAxis1, name='attention_scores') \n",
        "dotor = Dot(axes = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rc6wgVVq9gQU"
      },
      "outputs": [],
      "source": [
        "def one_step_attention(a, s_prev): # (hidden,vecter)\n",
        "    print(type(a))\n",
        "    # Repeat the decoder hidden state to concat with encoder hidden states\n",
        "    s_prev = repeator(s_prev)\n",
        "    concat = concatenator([a,s_prev])\n",
        "    # attention function\n",
        "    e = fattn_1(concat)\n",
        "    energies =fattn_2(e)\n",
        "    # calculate attention_scores (softmax)\n",
        "    attention_scores = activator(energies)\n",
        "    #calculate a context vector\n",
        "    context = dotor([attention_scores,a])\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv475_JS9gQY"
      },
      "source": [
        "# The model\n",
        "--> https://drive.google.com/file/d/1dcBMZG_fxfawQChmM6b8OsWtX7jR6cI9/view?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "duCZrcle9gQa"
      },
      "outputs": [],
      "source": [
        "n_h = 32 #hidden dimensions for encoder \n",
        "n_s = 64 #hidden dimensions for decoder\n",
        "encoder_LSTM =  Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))\n",
        "decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n",
        "output_layer = Dense(output_vocab_size, activation=\"softmax\") #softmax output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uwYrnDV79gQf"
      },
      "outputs": [],
      "source": [
        "def model(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_h -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    vocab_size -- size of the input vocab\n",
        "    output_vocab_size -- size of the output vocab\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model\n",
        "    X = Input(shape=(Tx, vocab_size))\n",
        "    # Define hidden state and cell state for decoder_LSTM_Cell\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = list()\n",
        "\n",
        "    #Encoder Bi-LSTM\n",
        "    # h = BidirectionaM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))(X)\n",
        "    h = encoder_LSTM(X)\n",
        "    #Iterate for Ty steps (Decoding)\n",
        "    for t in range(Ty):\n",
        "    \n",
        "        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "        context = one_step_attention(h, s)\n",
        "       \n",
        "        # Feed the context vector to the decoder LSTM cell\n",
        "        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n",
        "           \n",
        "        # Pass the decoder hidden output to the output layer (softmax)\n",
        "        out = output_layer(s)\n",
        "        \n",
        "        # Append an output list with the current output\n",
        "        outputs.append(out)\n",
        "    \n",
        "    #Create model instance\n",
        "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-7k1D9DP9gQj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n"
          ]
        }
      ],
      "source": [
        "model = model(Tx, Ty, n_h, n_s, vocab_size, output_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lw3lcYN9gQp",
        "outputId": "404bebd2-3612-4d70-8903-f40accf62a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 27, 42)]     0           []                               \n",
            "                                                                                                  \n",
            " s0 (InputLayer)                [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 27, 64)      19200       ['input_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " repeat_vector_1 (RepeatVector)  (None, 27, 64)      0           ['s0[0][0]',                     \n",
            "                                                                  'lstm_3[0][0]',                 \n",
            "                                                                  'lstm_3[1][0]',                 \n",
            "                                                                  'lstm_3[2][0]',                 \n",
            "                                                                  'lstm_3[3][0]',                 \n",
            "                                                                  'lstm_3[4][0]',                 \n",
            "                                                                  'lstm_3[5][0]',                 \n",
            "                                                                  'lstm_3[6][0]',                 \n",
            "                                                                  'lstm_3[7][0]',                 \n",
            "                                                                  'lstm_3[8][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 27, 128)      0           ['bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[0][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[1][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[2][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[3][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[4][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[5][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[6][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[7][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[8][0]',        \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'repeat_vector_1[9][0]']        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 27, 10)       1290        ['concatenate_1[0][0]',          \n",
            "                                                                  'concatenate_1[1][0]',          \n",
            "                                                                  'concatenate_1[2][0]',          \n",
            "                                                                  'concatenate_1[3][0]',          \n",
            "                                                                  'concatenate_1[4][0]',          \n",
            "                                                                  'concatenate_1[5][0]',          \n",
            "                                                                  'concatenate_1[6][0]',          \n",
            "                                                                  'concatenate_1[7][0]',          \n",
            "                                                                  'concatenate_1[8][0]',          \n",
            "                                                                  'concatenate_1[9][0]']          \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 27, 1)        11          ['dense_3[0][0]',                \n",
            "                                                                  'dense_3[1][0]',                \n",
            "                                                                  'dense_3[2][0]',                \n",
            "                                                                  'dense_3[3][0]',                \n",
            "                                                                  'dense_3[4][0]',                \n",
            "                                                                  'dense_3[5][0]',                \n",
            "                                                                  'dense_3[6][0]',                \n",
            "                                                                  'dense_3[7][0]',                \n",
            "                                                                  'dense_3[8][0]',                \n",
            "                                                                  'dense_3[9][0]']                \n",
            "                                                                                                  \n",
            " attention_scores (Activation)  (None, 27, 1)        0           ['dense_4[0][0]',                \n",
            "                                                                  'dense_4[1][0]',                \n",
            "                                                                  'dense_4[2][0]',                \n",
            "                                                                  'dense_4[3][0]',                \n",
            "                                                                  'dense_4[4][0]',                \n",
            "                                                                  'dense_4[5][0]',                \n",
            "                                                                  'dense_4[6][0]',                \n",
            "                                                                  'dense_4[7][0]',                \n",
            "                                                                  'dense_4[8][0]',                \n",
            "                                                                  'dense_4[9][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1, 64)        0           ['attention_scores[0][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[1][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[2][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[3][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[4][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[5][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[6][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[7][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[8][0]',       \n",
            "                                                                  'bidirectional_1[0][0]',        \n",
            "                                                                  'attention_scores[9][0]',       \n",
            "                                                                  'bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, 64),         33024       ['dot_1[0][0]',                  \n",
            "                                 (None, 64),                      's0[0][0]',                     \n",
            "                                 (None, 64)]                      'c0[0][0]',                     \n",
            "                                                                  'dot_1[1][0]',                  \n",
            "                                                                  'lstm_3[0][0]',                 \n",
            "                                                                  'lstm_3[0][2]',                 \n",
            "                                                                  'dot_1[2][0]',                  \n",
            "                                                                  'lstm_3[1][0]',                 \n",
            "                                                                  'lstm_3[1][2]',                 \n",
            "                                                                  'dot_1[3][0]',                  \n",
            "                                                                  'lstm_3[2][0]',                 \n",
            "                                                                  'lstm_3[2][2]',                 \n",
            "                                                                  'dot_1[4][0]',                  \n",
            "                                                                  'lstm_3[3][0]',                 \n",
            "                                                                  'lstm_3[3][2]',                 \n",
            "                                                                  'dot_1[5][0]',                  \n",
            "                                                                  'lstm_3[4][0]',                 \n",
            "                                                                  'lstm_3[4][2]',                 \n",
            "                                                                  'dot_1[6][0]',                  \n",
            "                                                                  'lstm_3[5][0]',                 \n",
            "                                                                  'lstm_3[5][2]',                 \n",
            "                                                                  'dot_1[7][0]',                  \n",
            "                                                                  'lstm_3[6][0]',                 \n",
            "                                                                  'lstm_3[6][2]',                 \n",
            "                                                                  'dot_1[8][0]',                  \n",
            "                                                                  'lstm_3[7][0]',                 \n",
            "                                                                  'lstm_3[7][2]',                 \n",
            "                                                                  'dot_1[9][0]',                  \n",
            "                                                                  'lstm_3[8][0]',                 \n",
            "                                                                  'lstm_3[8][2]']                 \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 12)           780         ['lstm_3[0][0]',                 \n",
            "                                                                  'lstm_3[1][0]',                 \n",
            "                                                                  'lstm_3[2][0]',                 \n",
            "                                                                  'lstm_3[3][0]',                 \n",
            "                                                                  'lstm_3[4][0]',                 \n",
            "                                                                  'lstm_3[5][0]',                 \n",
            "                                                                  'lstm_3[6][0]',                 \n",
            "                                                                  'lstm_3[7][0]',                 \n",
            "                                                                  'lstm_3[8][0]',                 \n",
            "                                                                  'lstm_3[9][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54,305\n",
            "Trainable params: 54,305\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deHxUNrP9gQu",
        "outputId": "7cc20308-6166-4b7b-bfb1-df527a6ce995"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "opt = Adam(lr= 0.01, clipvalue=0.5)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "by_opLYU9gQz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15000\n",
            "(15000, 64)\n",
            "(15000, 64)\n"
          ]
        }
      ],
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Y.swapaxes(0,1))\n",
        "print(len(outputs[0]))\n",
        "print(s0.shape)\n",
        "print(c0.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1-xOEdH9gQ4",
        "outputId": "9b4bef59-579b-4ffb-86d7-0011bf4f55f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 23s 38ms/step - loss: 19.5630 - dense_5_loss: 1.5521 - dense_5_1_loss: 1.4015 - dense_5_2_loss: 1.8583 - dense_5_3_loss: 2.7992 - dense_5_4_loss: 1.2897 - dense_5_5_loss: 1.7565 - dense_5_6_loss: 2.7662 - dense_5_7_loss: 1.4283 - dense_5_8_loss: 1.9380 - dense_5_9_loss: 2.7730 - dense_5_accuracy: 0.3785 - dense_5_1_accuracy: 0.6819 - dense_5_2_accuracy: 0.3101 - dense_5_3_accuracy: 0.0803 - dense_5_4_accuracy: 0.9199 - dense_5_5_accuracy: 0.0371 - dense_5_6_accuracy: 0.0096 - dense_5_7_accuracy: 0.8858 - dense_5_8_accuracy: 0.1183 - dense_5_9_accuracy: 0.0645\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 11.8182 - dense_5_loss: 0.2502 - dense_5_1_loss: 0.2239 - dense_5_2_loss: 0.9607 - dense_5_3_loss: 2.3455 - dense_5_4_loss: 0.3270 - dense_5_5_loss: 0.7806 - dense_5_6_loss: 2.4924 - dense_5_7_loss: 0.5010 - dense_5_8_loss: 1.5050 - dense_5_9_loss: 2.4319 - dense_5_accuracy: 0.9646 - dense_5_1_accuracy: 0.9637 - dense_5_2_accuracy: 0.5758 - dense_5_3_accuracy: 0.1757 - dense_5_4_accuracy: 0.9991 - dense_5_5_accuracy: 0.6827 - dense_5_6_accuracy: 0.1135 - dense_5_7_accuracy: 0.9713 - dense_5_8_accuracy: 0.3716 - dense_5_9_accuracy: 0.1319\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 8.7494 - dense_5_loss: 0.1302 - dense_5_1_loss: 0.1041 - dense_5_2_loss: 0.7015 - dense_5_3_loss: 1.8878 - dense_5_4_loss: 0.0359 - dense_5_5_loss: 0.3464 - dense_5_6_loss: 2.0182 - dense_5_7_loss: 0.0261 - dense_5_8_loss: 1.2226 - dense_5_9_loss: 2.2766 - dense_5_accuracy: 0.9693 - dense_5_1_accuracy: 0.9694 - dense_5_2_accuracy: 0.7471 - dense_5_3_accuracy: 0.2843 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.8905 - dense_5_6_accuracy: 0.2423 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.4346 - dense_5_9_accuracy: 0.1397\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 7.9184 - dense_5_loss: 0.0891 - dense_5_1_loss: 0.0764 - dense_5_2_loss: 0.5507 - dense_5_3_loss: 1.6368 - dense_5_4_loss: 0.0204 - dense_5_5_loss: 0.2810 - dense_5_6_loss: 1.8148 - dense_5_7_loss: 0.0142 - dense_5_8_loss: 1.1794 - dense_5_9_loss: 2.2555 - dense_5_accuracy: 0.9738 - dense_5_1_accuracy: 0.9749 - dense_5_2_accuracy: 0.7975 - dense_5_3_accuracy: 0.3789 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9138 - dense_5_6_accuracy: 0.3275 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.4613 - dense_5_9_accuracy: 0.1572\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 7.1854 - dense_5_loss: 0.0709 - dense_5_1_loss: 0.0629 - dense_5_2_loss: 0.4464 - dense_5_3_loss: 1.3460 - dense_5_4_loss: 0.0153 - dense_5_5_loss: 0.2352 - dense_5_6_loss: 1.6156 - dense_5_7_loss: 0.0106 - dense_5_8_loss: 1.1517 - dense_5_9_loss: 2.2308 - dense_5_accuracy: 0.9752 - dense_5_1_accuracy: 0.9758 - dense_5_2_accuracy: 0.8291 - dense_5_3_accuracy: 0.4908 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9336 - dense_5_6_accuracy: 0.4027 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.4727 - dense_5_9_accuracy: 0.1691\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 6.6586 - dense_5_loss: 0.0604 - dense_5_1_loss: 0.0556 - dense_5_2_loss: 0.3921 - dense_5_3_loss: 1.1528 - dense_5_4_loss: 0.0117 - dense_5_5_loss: 0.2072 - dense_5_6_loss: 1.4186 - dense_5_7_loss: 0.0085 - dense_5_8_loss: 1.1399 - dense_5_9_loss: 2.2119 - dense_5_accuracy: 0.9770 - dense_5_1_accuracy: 0.9769 - dense_5_2_accuracy: 0.8387 - dense_5_3_accuracy: 0.5633 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9363 - dense_5_6_accuracy: 0.4978 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.4711 - dense_5_9_accuracy: 0.1734\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 6.2309 - dense_5_loss: 0.0525 - dense_5_1_loss: 0.0478 - dense_5_2_loss: 0.3570 - dense_5_3_loss: 1.0179 - dense_5_4_loss: 0.0093 - dense_5_5_loss: 0.1885 - dense_5_6_loss: 1.2324 - dense_5_7_loss: 0.0065 - dense_5_8_loss: 1.1256 - dense_5_9_loss: 2.1933 - dense_5_accuracy: 0.9785 - dense_5_1_accuracy: 0.9781 - dense_5_2_accuracy: 0.8445 - dense_5_3_accuracy: 0.6114 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9361 - dense_5_6_accuracy: 0.5795 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.4791 - dense_5_9_accuracy: 0.1787\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 5.8516 - dense_5_loss: 0.0480 - dense_5_1_loss: 0.0430 - dense_5_2_loss: 0.3324 - dense_5_3_loss: 0.9088 - dense_5_4_loss: 0.0069 - dense_5_5_loss: 0.1732 - dense_5_6_loss: 1.0678 - dense_5_7_loss: 0.0052 - dense_5_8_loss: 1.1029 - dense_5_9_loss: 2.1634 - dense_5_accuracy: 0.9803 - dense_5_1_accuracy: 0.9790 - dense_5_2_accuracy: 0.8489 - dense_5_3_accuracy: 0.6597 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9417 - dense_5_6_accuracy: 0.6487 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.4958 - dense_5_9_accuracy: 0.1937\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 5.4687 - dense_5_loss: 0.0422 - dense_5_1_loss: 0.0374 - dense_5_2_loss: 0.3109 - dense_5_3_loss: 0.7973 - dense_5_4_loss: 0.0058 - dense_5_5_loss: 0.1557 - dense_5_6_loss: 0.9263 - dense_5_7_loss: 0.0043 - dense_5_8_loss: 1.0749 - dense_5_9_loss: 2.1141 - dense_5_accuracy: 0.9815 - dense_5_1_accuracy: 0.9824 - dense_5_2_accuracy: 0.8490 - dense_5_3_accuracy: 0.7101 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9471 - dense_5_6_accuracy: 0.7103 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.5150 - dense_5_9_accuracy: 0.2162\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 5.1480 - dense_5_loss: 0.0380 - dense_5_1_loss: 0.0336 - dense_5_2_loss: 0.2978 - dense_5_3_loss: 0.6960 - dense_5_4_loss: 0.0048 - dense_5_5_loss: 0.1480 - dense_5_6_loss: 0.8291 - dense_5_7_loss: 0.0039 - dense_5_8_loss: 1.0382 - dense_5_9_loss: 2.0586 - dense_5_accuracy: 0.9852 - dense_5_1_accuracy: 0.9850 - dense_5_2_accuracy: 0.8563 - dense_5_3_accuracy: 0.7615 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9481 - dense_5_6_accuracy: 0.7445 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.5408 - dense_5_9_accuracy: 0.2392\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 4.8293 - dense_5_loss: 0.0312 - dense_5_1_loss: 0.0259 - dense_5_2_loss: 0.2804 - dense_5_3_loss: 0.5893 - dense_5_4_loss: 0.0042 - dense_5_5_loss: 0.1407 - dense_5_6_loss: 0.7503 - dense_5_7_loss: 0.0033 - dense_5_8_loss: 1.0051 - dense_5_9_loss: 1.9989 - dense_5_accuracy: 0.9904 - dense_5_1_accuracy: 0.9902 - dense_5_2_accuracy: 0.8626 - dense_5_3_accuracy: 0.8125 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9499 - dense_5_6_accuracy: 0.7678 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.5629 - dense_5_9_accuracy: 0.2611\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 4.5025 - dense_5_loss: 0.0235 - dense_5_1_loss: 0.0182 - dense_5_2_loss: 0.2655 - dense_5_3_loss: 0.4981 - dense_5_4_loss: 0.0038 - dense_5_5_loss: 0.1342 - dense_5_6_loss: 0.6752 - dense_5_7_loss: 0.0029 - dense_5_8_loss: 0.9671 - dense_5_9_loss: 1.9139 - dense_5_accuracy: 0.9938 - dense_5_1_accuracy: 0.9940 - dense_5_2_accuracy: 0.8670 - dense_5_3_accuracy: 0.8494 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9523 - dense_5_6_accuracy: 0.7939 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.5896 - dense_5_9_accuracy: 0.2890\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 4.1923 - dense_5_loss: 0.0180 - dense_5_1_loss: 0.0120 - dense_5_2_loss: 0.2543 - dense_5_3_loss: 0.4187 - dense_5_4_loss: 0.0035 - dense_5_5_loss: 0.1299 - dense_5_6_loss: 0.6146 - dense_5_7_loss: 0.0028 - dense_5_8_loss: 0.9252 - dense_5_9_loss: 1.8133 - dense_5_accuracy: 0.9965 - dense_5_1_accuracy: 0.9968 - dense_5_2_accuracy: 0.8755 - dense_5_3_accuracy: 0.8795 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9527 - dense_5_6_accuracy: 0.8079 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.6127 - dense_5_9_accuracy: 0.3211\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 3.8341 - dense_5_loss: 0.0148 - dense_5_1_loss: 0.0084 - dense_5_2_loss: 0.2412 - dense_5_3_loss: 0.3509 - dense_5_4_loss: 0.0033 - dense_5_5_loss: 0.1298 - dense_5_6_loss: 0.5628 - dense_5_7_loss: 0.0026 - dense_5_8_loss: 0.8650 - dense_5_9_loss: 1.6552 - dense_5_accuracy: 0.9984 - dense_5_1_accuracy: 0.9987 - dense_5_2_accuracy: 0.8775 - dense_5_3_accuracy: 0.9045 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9515 - dense_5_6_accuracy: 0.8215 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.6513 - dense_5_9_accuracy: 0.3791\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 3.4700 - dense_5_loss: 0.0132 - dense_5_1_loss: 0.0067 - dense_5_2_loss: 0.2310 - dense_5_3_loss: 0.2983 - dense_5_4_loss: 0.0031 - dense_5_5_loss: 0.1324 - dense_5_6_loss: 0.5245 - dense_5_7_loss: 0.0027 - dense_5_8_loss: 0.7886 - dense_5_9_loss: 1.4698 - dense_5_accuracy: 0.9987 - dense_5_1_accuracy: 0.9991 - dense_5_2_accuracy: 0.8838 - dense_5_3_accuracy: 0.9248 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9507 - dense_5_6_accuracy: 0.8323 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.6877 - dense_5_9_accuracy: 0.4431\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 3.0704 - dense_5_loss: 0.0116 - dense_5_1_loss: 0.0053 - dense_5_2_loss: 0.2207 - dense_5_3_loss: 0.2569 - dense_5_4_loss: 0.0028 - dense_5_5_loss: 0.1274 - dense_5_6_loss: 0.4863 - dense_5_7_loss: 0.0025 - dense_5_8_loss: 0.7028 - dense_5_9_loss: 1.2541 - dense_5_accuracy: 0.9994 - dense_5_1_accuracy: 0.9994 - dense_5_2_accuracy: 0.8876 - dense_5_3_accuracy: 0.9338 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9523 - dense_5_6_accuracy: 0.8435 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.7251 - dense_5_9_accuracy: 0.5244\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 2.6966 - dense_5_loss: 0.0105 - dense_5_1_loss: 0.0045 - dense_5_2_loss: 0.2151 - dense_5_3_loss: 0.2259 - dense_5_4_loss: 0.0026 - dense_5_5_loss: 0.1194 - dense_5_6_loss: 0.4321 - dense_5_7_loss: 0.0023 - dense_5_8_loss: 0.6447 - dense_5_9_loss: 1.0395 - dense_5_accuracy: 0.9998 - dense_5_1_accuracy: 0.9997 - dense_5_2_accuracy: 0.8913 - dense_5_3_accuracy: 0.9452 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9553 - dense_5_6_accuracy: 0.8629 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.7420 - dense_5_9_accuracy: 0.6096\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 2.3653 - dense_5_loss: 0.0095 - dense_5_1_loss: 0.0045 - dense_5_2_loss: 0.2059 - dense_5_3_loss: 0.1950 - dense_5_4_loss: 0.0025 - dense_5_5_loss: 0.1119 - dense_5_6_loss: 0.3849 - dense_5_7_loss: 0.0020 - dense_5_8_loss: 0.5929 - dense_5_9_loss: 0.8562 - dense_5_accuracy: 0.9995 - dense_5_1_accuracy: 0.9995 - dense_5_2_accuracy: 0.8943 - dense_5_3_accuracy: 0.9538 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9578 - dense_5_6_accuracy: 0.8773 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.7590 - dense_5_9_accuracy: 0.6776\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 2.0862 - dense_5_loss: 0.0089 - dense_5_1_loss: 0.0037 - dense_5_2_loss: 0.1951 - dense_5_3_loss: 0.1680 - dense_5_4_loss: 0.0023 - dense_5_5_loss: 0.1047 - dense_5_6_loss: 0.3367 - dense_5_7_loss: 0.0020 - dense_5_8_loss: 0.5426 - dense_5_9_loss: 0.7222 - dense_5_accuracy: 0.9999 - dense_5_1_accuracy: 0.9999 - dense_5_2_accuracy: 0.9033 - dense_5_3_accuracy: 0.9633 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9603 - dense_5_6_accuracy: 0.8960 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.7799 - dense_5_9_accuracy: 0.7223\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 1.8397 - dense_5_loss: 0.0074 - dense_5_1_loss: 0.0030 - dense_5_2_loss: 0.1858 - dense_5_3_loss: 0.1443 - dense_5_4_loss: 0.0021 - dense_5_5_loss: 0.0965 - dense_5_6_loss: 0.2975 - dense_5_7_loss: 0.0019 - dense_5_8_loss: 0.4801 - dense_5_9_loss: 0.6213 - dense_5_accuracy: 0.9999 - dense_5_1_accuracy: 0.9999 - dense_5_2_accuracy: 0.9063 - dense_5_3_accuracy: 0.9710 - dense_5_4_accuracy: 0.9999 - dense_5_5_accuracy: 0.9621 - dense_5_6_accuracy: 0.9079 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.8031 - dense_5_9_accuracy: 0.7543\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x24bb1b34a30>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit([X, s0, c0], outputs, epochs=20, batch_size=120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePf2CDQb9gQ-"
      },
      "source": [
        "# Let's do some \"translation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJdBoaJE9gRA",
        "outputId": "d4826096-52f1-4285-f20a-4d923de16485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1999-05-23\n",
            "2009-10-05\n",
            "2016-08-03\n",
            "2000-07-11\n",
            "2018-05-19\n",
            "2011-03-33\n",
            "2011-03-11\n"
          ]
        }
      ],
      "source": [
        "def prep_input(input_list):\n",
        "    X = []\n",
        "    for line in input_list:\n",
        "        temp=[]\n",
        "        for char in line:\n",
        "            temp.append(char_to_ix[char])\n",
        "        X.append(temp)\n",
        "    X = pad_sequences(X,maxlen=maxlen)\n",
        "    X= to_categorical(X,vocab_size)\n",
        "    X=X.reshape(len(input_list),maxlen ,vocab_size)\n",
        "    \n",
        "    return X\n",
        "\n",
        "EXAMPLES = ['3 May 1999', '05 October 2009', '30 August 2016', '11 July 2000', 'Saturday 19 May 2018', '3 March 2001', '1 March 2001']\n",
        "s0 = np.zeros((len(EXAMPLES), n_s))\n",
        "c0 = np.zeros((len(EXAMPLES), n_s))\n",
        "EXAMPLES = prep_input(EXAMPLES)\n",
        "\n",
        "prediction = model.predict([EXAMPLES , s0, c0])\n",
        "prediction = np.swapaxes(prediction,0,1)\n",
        "prediction = np.argmax(prediction, axis = -1)\n",
        "\n",
        "for j in range(len(prediction)):\n",
        "    output = \"\".join([ix_to_output_char[int(i)] for i in prediction[j]])\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_um44CnrVCsp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
