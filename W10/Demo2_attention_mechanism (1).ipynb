{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB0ipHig9gOm"
      },
      "source": [
        "# Attention Mechanism Demo on Keras: Machine Translation Example (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this demo, we will show you how to create a machine translator using Keras. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. (Programming Assignment: Neural Machine Translation with Attention)    In this demo, we create a machine translator to translate dates in various formats  into dates in an ISO format. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_clL4w89gOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89af5dcc-34a6-48d1-f0bb-c5b4382c670c"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEyHEfFt9gO9"
      },
      "source": [
        "## Generate Dataset\n",
        "We generate a toy dataset using datetime library.  A target output only comes in one format (iso format), while there are three different date format for an input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWRgqvwY9gO_"
      },
      "source": [
        "#Generating a toy dataset\n",
        "import datetime\n",
        "base = datetime.datetime.today()\n",
        "base = datetime.date(base.year, base.month, base.day)\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 15000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrNHzgFy9gPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a35f39-347e-4462-f1cb-b17c979a72a3"
      },
      "source": [
        "target_date_list = [date.isoformat() for date in date_list] \n",
        "print(target_date_list[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT7V4FJL9gPR"
      },
      "source": [
        "from random import randint\n",
        "random.seed(42)\n",
        "input_date_list = list()\n",
        "for date in date_list:\n",
        "    random_num = randint(0, 2)\n",
        "    if random_num == 0:\n",
        "        input_date_list.append(date.strftime(\"%d/%m/%y\"))#\"11/03/02\"\n",
        "    elif random_num == 1:\n",
        "        input_date_list.append(date.strftime(\"%A %d %B %Y\")) #\"Monday 11 March 2002\"\n",
        "    elif random_num == 2: \n",
        "        input_date_list.append(date.strftime(\"%d %B %Y\")) #\"11 March 2002\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isfXKy2y9gPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d89f5f9-5e4f-4ee9-ab11-a32d6c711659"
      },
      "source": [
        "for input_sample, target_sample in zip(input_date_list[0:10],target_date_list[0:10]):\n",
        "    print(input_sample,target_sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 March 2023 2023-03-30\n",
            "29/03/23 2023-03-29\n",
            "28/03/23 2023-03-28\n",
            "27 March 2023 2023-03-27\n",
            "Sunday 26 March 2023 2023-03-26\n",
            "25/03/23 2023-03-25\n",
            "24/03/23 2023-03-24\n",
            "23/03/23 2023-03-23\n",
            "22 March 2023 2023-03-22\n",
            "21/03/23 2023-03-21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KndjKsS9gPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ae3f66-8d05-44cd-c925-51999ed618ab"
      },
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(input_date_list)))\n",
        "output_chars = list(set(''.join(target_date_list)))\n",
        "\n",
        "# +1 for padding\n",
        "data_size, vocab_size = len(input_date_list), len(input_chars)+1 \n",
        "output_vocab_size = len(output_chars)+1\n",
        "\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(input_date_list, key=len)) #max input length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 15000 lines and 42 unique characters in your input data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K-0kaUH9gPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49f0186-7fdd-4f73-c631-edd3786b2de3"
      },
      "source": [
        "print(\"Max input length:\", maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input length: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCSo8cR29gPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc98c52-e3a7-4264-f39e-79c9ce863337"
      },
      "source": [
        "sorted_chars= sorted(input_chars)\n",
        "sorted_output_chars= sorted(output_chars)\n",
        "sorted_chars.insert(0,\"<PAD>\") #PADDING for input\n",
        "sorted_output_chars.insert(0,\"<PAD>\") #PADDING for output\n",
        "#Input\n",
        "char_to_ix = { ch:i for i,ch in enumerate(sorted_chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(sorted_chars) } #reverse dictionary\n",
        "#Output\n",
        "output_char_to_ix = { ch:i for i,ch in enumerate(sorted_output_chars) }\n",
        "ix_to_output_char = { i:ch for i,ch in enumerate(sorted_output_chars) } #reverse dictionary\n",
        "\n",
        "print(ix_to_char)\n",
        "print(ix_to_output_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '<PAD>', 1: ' ', 2: '/', 3: '0', 4: '1', 5: '2', 6: '3', 7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: 'A', 14: 'D', 15: 'F', 16: 'J', 17: 'M', 18: 'N', 19: 'O', 20: 'S', 21: 'T', 22: 'W', 23: 'a', 24: 'b', 25: 'c', 26: 'd', 27: 'e', 28: 'g', 29: 'h', 30: 'i', 31: 'l', 32: 'm', 33: 'n', 34: 'o', 35: 'p', 36: 'r', 37: 's', 38: 't', 39: 'u', 40: 'v', 41: 'y'}\n",
            "{0: '<PAD>', 1: '-', 2: '0', 3: '1', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q0XsxhL9gP2"
      },
      "source": [
        "m=15000  # #sample\n",
        "Tx=maxlen # size of input = 27\n",
        "Ty=10 # size of output = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvKOfVnc9gP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1581e27e-5f01-4b69-972c-84d65540758e"
      },
      "source": [
        "X = []\n",
        "for line in input_date_list:\n",
        "    temp=[]\n",
        "    for char in line:\n",
        "        temp.append(char_to_ix[char])\n",
        "    X.append(temp)\n",
        "Y = []\n",
        "for line in target_date_list:\n",
        "    temp=[]\n",
        "    for char in line:\n",
        "        temp.append(output_char_to_ix[char])\n",
        "    Y.append(temp)    \n",
        "\n",
        "X = pad_sequences(X,maxlen=maxlen)\n",
        "# Y = pad_sequences(Y,maxlen=10)\n",
        "\n",
        "X= to_categorical(X,vocab_size)\n",
        "X=X.reshape(data_size,maxlen ,vocab_size)\n",
        "\n",
        "Y= to_categorical(Y,output_vocab_size)\n",
        "Y=Y.reshape(data_size,10 ,output_vocab_size)\n",
        "print(X.shape,Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15000, 27, 42) (15000, 10, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFYhwzdj9gQG"
      },
      "source": [
        "# Attention Mechanism\n",
        "--> https://drive.google.com/file/d/1xY2_yGARtR8MDw231j7OmH-zCB4XiOkl/view?usp=share_link "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76X7VMpD9gQI"
      },
      "source": [
        "from tensorflow.keras.activations import softmax\n",
        "def softMaxAxis1(x):\n",
        "    return softmax(x,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhngrOGI9gQO"
      },
      "source": [
        "#These are global variables (shared layers)\n",
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "#Attention function###\n",
        "fattn_1 = Dense(10, activation = \"tanh\")\n",
        "fattn_2 = Dense(1, activation = \"relu\")\n",
        "###\n",
        "activator = Activation(softMaxAxis1, name='attention_scores') \n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc6wgVVq9gQU"
      },
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "\n",
        "    # Repeat the decoder hidden state to concat with encoder hidden states\n",
        "    s_prev = repeator(s_prev)\n",
        "    concat = concatenator([a,s_prev])\n",
        "    # attention function\n",
        "    e = fattn_1(concat)\n",
        "    energies =fattn_2(e)\n",
        "    # calculate attention_scores (softmax)\n",
        "    attention_scores = activator(energies)\n",
        "    #calculate a context vector\n",
        "    context = dotor([attention_scores,a])\n",
        "\n",
        "    return context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv475_JS9gQY"
      },
      "source": [
        "# The model\n",
        "--> https://drive.google.com/file/d/1dcBMZG_fxfawQChmM6b8OsWtX7jR6cI9/view?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duCZrcle9gQa"
      },
      "source": [
        "n_h = 32 #hidden dimensions for encoder \n",
        "n_s = 64 #hidden dimensions for decoder\n",
        "encoder_LSTM =  Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))\n",
        "decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n",
        "output_layer = Dense(output_vocab_size, activation=\"softmax\") #softmax output layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwYrnDV79gQf"
      },
      "source": [
        "def model(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_h -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    vocab_size -- size of the input vocab\n",
        "    output_vocab_size -- size of the output vocab\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model\n",
        "    X = Input(shape=(Tx, vocab_size))\n",
        "    # Define hidden state and cell state for decoder_LSTM_Cell\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = list()\n",
        "\n",
        "    #Encoder Bi-LSTM\n",
        "    # h = Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))(X)\n",
        "    h = encoder_LSTM(X)\n",
        "    #Iterate for Ty steps (Decoding)\n",
        "    for t in range(Ty):\n",
        "    \n",
        "        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "        context = one_step_attention(h, s)\n",
        "       \n",
        "        # Feed the context vector to the decoder LSTM cell\n",
        "        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n",
        "           \n",
        "        # Pass the decoder hidden output to the output layer (softmax)\n",
        "        out = output_layer(s)\n",
        "        \n",
        "        # Append an output list with the current output\n",
        "        outputs.append(out)\n",
        "    \n",
        "    #Create model instance\n",
        "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7k1D9DP9gQj"
      },
      "source": [
        "model = model(Tx, Ty, n_h, n_s, vocab_size, output_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lw3lcYN9gQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404bebd2-3612-4d70-8903-f40accf62a9c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 27, 42)]     0           []                               \n",
            "                                                                                                  \n",
            " s0 (InputLayer)                [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 27, 64)       19200       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (None, 27, 64)       0           ['s0[0][0]',                     \n",
            "                                                                  'lstm_1[0][0]',                 \n",
            "                                                                  'lstm_1[1][0]',                 \n",
            "                                                                  'lstm_1[2][0]',                 \n",
            "                                                                  'lstm_1[3][0]',                 \n",
            "                                                                  'lstm_1[4][0]',                 \n",
            "                                                                  'lstm_1[5][0]',                 \n",
            "                                                                  'lstm_1[6][0]',                 \n",
            "                                                                  'lstm_1[7][0]',                 \n",
            "                                                                  'lstm_1[8][0]']                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 27, 128)      0           ['bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[0][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[1][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[2][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[3][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[4][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[5][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[6][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[7][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[8][0]',          \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'repeat_vector[9][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 27, 10)       1290        ['concatenate[0][0]',            \n",
            "                                                                  'concatenate[1][0]',            \n",
            "                                                                  'concatenate[2][0]',            \n",
            "                                                                  'concatenate[3][0]',            \n",
            "                                                                  'concatenate[4][0]',            \n",
            "                                                                  'concatenate[5][0]',            \n",
            "                                                                  'concatenate[6][0]',            \n",
            "                                                                  'concatenate[7][0]',            \n",
            "                                                                  'concatenate[8][0]',            \n",
            "                                                                  'concatenate[9][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 27, 1)        11          ['dense[0][0]',                  \n",
            "                                                                  'dense[1][0]',                  \n",
            "                                                                  'dense[2][0]',                  \n",
            "                                                                  'dense[3][0]',                  \n",
            "                                                                  'dense[4][0]',                  \n",
            "                                                                  'dense[5][0]',                  \n",
            "                                                                  'dense[6][0]',                  \n",
            "                                                                  'dense[7][0]',                  \n",
            "                                                                  'dense[8][0]',                  \n",
            "                                                                  'dense[9][0]']                  \n",
            "                                                                                                  \n",
            " attention_scores (Activation)  (None, 27, 1)        0           ['dense_1[0][0]',                \n",
            "                                                                  'dense_1[1][0]',                \n",
            "                                                                  'dense_1[2][0]',                \n",
            "                                                                  'dense_1[3][0]',                \n",
            "                                                                  'dense_1[4][0]',                \n",
            "                                                                  'dense_1[5][0]',                \n",
            "                                                                  'dense_1[6][0]',                \n",
            "                                                                  'dense_1[7][0]',                \n",
            "                                                                  'dense_1[8][0]',                \n",
            "                                                                  'dense_1[9][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 1, 64)        0           ['attention_scores[0][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[1][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[2][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[3][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[4][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[5][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[6][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[7][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[8][0]',       \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'attention_scores[9][0]',       \n",
            "                                                                  'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 64),         33024       ['dot[0][0]',                    \n",
            "                                 (None, 64),                      's0[0][0]',                     \n",
            "                                 (None, 64)]                      'c0[0][0]',                     \n",
            "                                                                  'dot[1][0]',                    \n",
            "                                                                  'lstm_1[0][0]',                 \n",
            "                                                                  'lstm_1[0][2]',                 \n",
            "                                                                  'dot[2][0]',                    \n",
            "                                                                  'lstm_1[1][0]',                 \n",
            "                                                                  'lstm_1[1][2]',                 \n",
            "                                                                  'dot[3][0]',                    \n",
            "                                                                  'lstm_1[2][0]',                 \n",
            "                                                                  'lstm_1[2][2]',                 \n",
            "                                                                  'dot[4][0]',                    \n",
            "                                                                  'lstm_1[3][0]',                 \n",
            "                                                                  'lstm_1[3][2]',                 \n",
            "                                                                  'dot[5][0]',                    \n",
            "                                                                  'lstm_1[4][0]',                 \n",
            "                                                                  'lstm_1[4][2]',                 \n",
            "                                                                  'dot[6][0]',                    \n",
            "                                                                  'lstm_1[5][0]',                 \n",
            "                                                                  'lstm_1[5][2]',                 \n",
            "                                                                  'dot[7][0]',                    \n",
            "                                                                  'lstm_1[6][0]',                 \n",
            "                                                                  'lstm_1[6][2]',                 \n",
            "                                                                  'dot[8][0]',                    \n",
            "                                                                  'lstm_1[7][0]',                 \n",
            "                                                                  'lstm_1[7][2]',                 \n",
            "                                                                  'dot[9][0]',                    \n",
            "                                                                  'lstm_1[8][0]',                 \n",
            "                                                                  'lstm_1[8][2]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 12)           780         ['lstm_1[0][0]',                 \n",
            "                                                                  'lstm_1[1][0]',                 \n",
            "                                                                  'lstm_1[2][0]',                 \n",
            "                                                                  'lstm_1[3][0]',                 \n",
            "                                                                  'lstm_1[4][0]',                 \n",
            "                                                                  'lstm_1[5][0]',                 \n",
            "                                                                  'lstm_1[6][0]',                 \n",
            "                                                                  'lstm_1[7][0]',                 \n",
            "                                                                  'lstm_1[8][0]',                 \n",
            "                                                                  'lstm_1[9][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54,305\n",
            "Trainable params: 54,305\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deHxUNrP9gQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc20308-6166-4b7b-bfb1-df527a6ce995"
      },
      "source": [
        "opt = Adam(lr= 0.01, clipvalue=0.5)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by_opLYU9gQz"
      },
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Y.swapaxes(0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1-xOEdH9gQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4bef59-579b-4ffb-86d7-0011bf4f55f5"
      },
      "source": [
        "model.fit([X, s0, c0], outputs, epochs=20, batch_size=120)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 27s 27ms/step - loss: 19.6175 - dense_2_loss: 1.5747 - dense_2_1_loss: 1.4345 - dense_2_2_loss: 1.8829 - dense_2_3_loss: 2.7965 - dense_2_4_loss: 1.2940 - dense_2_5_loss: 1.7290 - dense_2_6_loss: 2.7629 - dense_2_7_loss: 1.4290 - dense_2_8_loss: 1.9367 - dense_2_9_loss: 2.7774 - dense_2_accuracy: 0.3451 - dense_2_1_accuracy: 0.6755 - dense_2_2_accuracy: 0.3169 - dense_2_3_accuracy: 0.0883 - dense_2_4_accuracy: 0.8683 - dense_2_5_accuracy: 0.0659 - dense_2_6_accuracy: 0.0124 - dense_2_7_accuracy: 0.8332 - dense_2_8_accuracy: 0.1299 - dense_2_9_accuracy: 0.0671\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 11.6160 - dense_2_loss: 0.2872 - dense_2_1_loss: 0.2284 - dense_2_2_loss: 0.9724 - dense_2_3_loss: 2.3141 - dense_2_4_loss: 0.2884 - dense_2_5_loss: 0.7365 - dense_2_6_loss: 2.4369 - dense_2_7_loss: 0.4504 - dense_2_8_loss: 1.4755 - dense_2_9_loss: 2.4261 - dense_2_accuracy: 0.9665 - dense_2_1_accuracy: 0.9668 - dense_2_2_accuracy: 0.5796 - dense_2_3_accuracy: 0.1741 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.7525 - dense_2_6_accuracy: 0.1321 - dense_2_7_accuracy: 0.9671 - dense_2_8_accuracy: 0.3743 - dense_2_9_accuracy: 0.1281\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 3s 28ms/step - loss: 8.6431 - dense_2_loss: 0.1388 - dense_2_1_loss: 0.1132 - dense_2_2_loss: 0.6825 - dense_2_3_loss: 1.8089 - dense_2_4_loss: 0.0346 - dense_2_5_loss: 0.3458 - dense_2_6_loss: 1.9908 - dense_2_7_loss: 0.0299 - dense_2_8_loss: 1.2208 - dense_2_9_loss: 2.2778 - dense_2_accuracy: 0.9707 - dense_2_1_accuracy: 0.9709 - dense_2_2_accuracy: 0.7381 - dense_2_3_accuracy: 0.3026 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.8969 - dense_2_6_accuracy: 0.2557 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.4367 - dense_2_9_accuracy: 0.1421\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 3s 28ms/step - loss: 7.7716 - dense_2_loss: 0.0945 - dense_2_1_loss: 0.0805 - dense_2_2_loss: 0.5204 - dense_2_3_loss: 1.4897 - dense_2_4_loss: 0.0219 - dense_2_5_loss: 0.2684 - dense_2_6_loss: 1.8310 - dense_2_7_loss: 0.0147 - dense_2_8_loss: 1.1952 - dense_2_9_loss: 2.2553 - dense_2_accuracy: 0.9752 - dense_2_1_accuracy: 0.9751 - dense_2_2_accuracy: 0.7969 - dense_2_3_accuracy: 0.4271 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9270 - dense_2_6_accuracy: 0.3197 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.4456 - dense_2_9_accuracy: 0.1519\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 4s 31ms/step - loss: 7.1482 - dense_2_loss: 0.0710 - dense_2_1_loss: 0.0625 - dense_2_2_loss: 0.4299 - dense_2_3_loss: 1.2761 - dense_2_4_loss: 0.0163 - dense_2_5_loss: 0.2211 - dense_2_6_loss: 1.6443 - dense_2_7_loss: 0.0103 - dense_2_8_loss: 1.1717 - dense_2_9_loss: 2.2451 - dense_2_accuracy: 0.9759 - dense_2_1_accuracy: 0.9762 - dense_2_2_accuracy: 0.8301 - dense_2_3_accuracy: 0.5117 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9365 - dense_2_6_accuracy: 0.3901 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.4577 - dense_2_9_accuracy: 0.1597\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 4s 30ms/step - loss: 6.6915 - dense_2_loss: 0.0562 - dense_2_1_loss: 0.0493 - dense_2_2_loss: 0.3754 - dense_2_3_loss: 1.1284 - dense_2_4_loss: 0.0129 - dense_2_5_loss: 0.1984 - dense_2_6_loss: 1.4791 - dense_2_7_loss: 0.0081 - dense_2_8_loss: 1.1566 - dense_2_9_loss: 2.2272 - dense_2_accuracy: 0.9785 - dense_2_1_accuracy: 0.9789 - dense_2_2_accuracy: 0.8432 - dense_2_3_accuracy: 0.5583 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9381 - dense_2_6_accuracy: 0.4766 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.4643 - dense_2_9_accuracy: 0.1725\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 4s 28ms/step - loss: 6.2950 - dense_2_loss: 0.0494 - dense_2_1_loss: 0.0429 - dense_2_2_loss: 0.3427 - dense_2_3_loss: 1.0154 - dense_2_4_loss: 0.0105 - dense_2_5_loss: 0.1799 - dense_2_6_loss: 1.3099 - dense_2_7_loss: 0.0067 - dense_2_8_loss: 1.1390 - dense_2_9_loss: 2.1988 - dense_2_accuracy: 0.9793 - dense_2_1_accuracy: 0.9807 - dense_2_2_accuracy: 0.8515 - dense_2_3_accuracy: 0.6069 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9413 - dense_2_6_accuracy: 0.5487 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.4701 - dense_2_9_accuracy: 0.1879\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 4s 28ms/step - loss: 5.9028 - dense_2_loss: 0.0442 - dense_2_1_loss: 0.0369 - dense_2_2_loss: 0.3162 - dense_2_3_loss: 0.8858 - dense_2_4_loss: 0.0091 - dense_2_5_loss: 0.1675 - dense_2_6_loss: 1.1485 - dense_2_7_loss: 0.0062 - dense_2_8_loss: 1.1229 - dense_2_9_loss: 2.1655 - dense_2_accuracy: 0.9818 - dense_2_1_accuracy: 0.9834 - dense_2_2_accuracy: 0.8576 - dense_2_3_accuracy: 0.6679 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9452 - dense_2_6_accuracy: 0.6179 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.4759 - dense_2_9_accuracy: 0.2019\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 5.5007 - dense_2_loss: 0.0373 - dense_2_1_loss: 0.0308 - dense_2_2_loss: 0.2956 - dense_2_3_loss: 0.7568 - dense_2_4_loss: 0.0072 - dense_2_5_loss: 0.1556 - dense_2_6_loss: 1.0024 - dense_2_7_loss: 0.0058 - dense_2_8_loss: 1.0909 - dense_2_9_loss: 2.1183 - dense_2_accuracy: 0.9851 - dense_2_1_accuracy: 0.9862 - dense_2_2_accuracy: 0.8675 - dense_2_3_accuracy: 0.7293 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9471 - dense_2_6_accuracy: 0.6660 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.4964 - dense_2_9_accuracy: 0.2171\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 3s 28ms/step - loss: 5.1207 - dense_2_loss: 0.0314 - dense_2_1_loss: 0.0251 - dense_2_2_loss: 0.2754 - dense_2_3_loss: 0.6395 - dense_2_4_loss: 0.0064 - dense_2_5_loss: 0.1484 - dense_2_6_loss: 0.8932 - dense_2_7_loss: 0.0051 - dense_2_8_loss: 1.0482 - dense_2_9_loss: 2.0480 - dense_2_accuracy: 0.9885 - dense_2_1_accuracy: 0.9899 - dense_2_2_accuracy: 0.8736 - dense_2_3_accuracy: 0.7741 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9498 - dense_2_6_accuracy: 0.7053 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.5183 - dense_2_9_accuracy: 0.2382\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 3s 28ms/step - loss: 4.7772 - dense_2_loss: 0.0243 - dense_2_1_loss: 0.0189 - dense_2_2_loss: 0.2581 - dense_2_3_loss: 0.5639 - dense_2_4_loss: 0.0057 - dense_2_5_loss: 0.1449 - dense_2_6_loss: 0.8246 - dense_2_7_loss: 0.0048 - dense_2_8_loss: 0.9979 - dense_2_9_loss: 1.9340 - dense_2_accuracy: 0.9927 - dense_2_1_accuracy: 0.9930 - dense_2_2_accuracy: 0.8806 - dense_2_3_accuracy: 0.8089 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9487 - dense_2_6_accuracy: 0.7235 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.5489 - dense_2_9_accuracy: 0.2769\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 4.4106 - dense_2_loss: 0.0183 - dense_2_1_loss: 0.0130 - dense_2_2_loss: 0.2408 - dense_2_3_loss: 0.4809 - dense_2_4_loss: 0.0054 - dense_2_5_loss: 0.1409 - dense_2_6_loss: 0.7881 - dense_2_7_loss: 0.0045 - dense_2_8_loss: 0.9355 - dense_2_9_loss: 1.7831 - dense_2_accuracy: 0.9957 - dense_2_1_accuracy: 0.9959 - dense_2_2_accuracy: 0.8893 - dense_2_3_accuracy: 0.8513 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9515 - dense_2_6_accuracy: 0.7315 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.5821 - dense_2_9_accuracy: 0.3271\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 3s 28ms/step - loss: 3.9749 - dense_2_loss: 0.0151 - dense_2_1_loss: 0.0095 - dense_2_2_loss: 0.2268 - dense_2_3_loss: 0.4106 - dense_2_4_loss: 0.0053 - dense_2_5_loss: 0.1408 - dense_2_6_loss: 0.7624 - dense_2_7_loss: 0.0044 - dense_2_8_loss: 0.8309 - dense_2_9_loss: 1.5692 - dense_2_accuracy: 0.9971 - dense_2_1_accuracy: 0.9973 - dense_2_2_accuracy: 0.8973 - dense_2_3_accuracy: 0.8874 - dense_2_4_accuracy: 0.9999 - dense_2_5_accuracy: 0.9494 - dense_2_6_accuracy: 0.7317 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.6433 - dense_2_9_accuracy: 0.4048\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 4s 28ms/step - loss: 3.5457 - dense_2_loss: 0.0133 - dense_2_1_loss: 0.0072 - dense_2_2_loss: 0.2073 - dense_2_3_loss: 0.3347 - dense_2_4_loss: 0.0054 - dense_2_5_loss: 0.1361 - dense_2_6_loss: 0.7358 - dense_2_7_loss: 0.0045 - dense_2_8_loss: 0.7333 - dense_2_9_loss: 1.3681 - dense_2_accuracy: 0.9979 - dense_2_1_accuracy: 0.9979 - dense_2_2_accuracy: 0.9105 - dense_2_3_accuracy: 0.9223 - dense_2_4_accuracy: 0.9999 - dense_2_5_accuracy: 0.9507 - dense_2_6_accuracy: 0.7413 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.6961 - dense_2_9_accuracy: 0.4734\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 3.1989 - dense_2_loss: 0.0111 - dense_2_1_loss: 0.0051 - dense_2_2_loss: 0.1898 - dense_2_3_loss: 0.2759 - dense_2_4_loss: 0.0046 - dense_2_5_loss: 0.1259 - dense_2_6_loss: 0.6884 - dense_2_7_loss: 0.0040 - dense_2_8_loss: 0.6704 - dense_2_9_loss: 1.2238 - dense_2_accuracy: 0.9985 - dense_2_1_accuracy: 0.9989 - dense_2_2_accuracy: 0.9205 - dense_2_3_accuracy: 0.9429 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9549 - dense_2_6_accuracy: 0.7558 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.7259 - dense_2_9_accuracy: 0.5215\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 4s 28ms/step - loss: 2.8881 - dense_2_loss: 0.0090 - dense_2_1_loss: 0.0035 - dense_2_2_loss: 0.1692 - dense_2_3_loss: 0.2314 - dense_2_4_loss: 0.0039 - dense_2_5_loss: 0.1161 - dense_2_6_loss: 0.6325 - dense_2_7_loss: 0.0035 - dense_2_8_loss: 0.6225 - dense_2_9_loss: 1.0964 - dense_2_accuracy: 0.9995 - dense_2_1_accuracy: 0.9996 - dense_2_2_accuracy: 0.9339 - dense_2_3_accuracy: 0.9550 - dense_2_4_accuracy: 0.9999 - dense_2_5_accuracy: 0.9583 - dense_2_6_accuracy: 0.7756 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.7447 - dense_2_9_accuracy: 0.5691\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 4s 28ms/step - loss: 2.6201 - dense_2_loss: 0.0089 - dense_2_1_loss: 0.0036 - dense_2_2_loss: 0.1548 - dense_2_3_loss: 0.2010 - dense_2_4_loss: 0.0035 - dense_2_5_loss: 0.1107 - dense_2_6_loss: 0.5927 - dense_2_7_loss: 0.0031 - dense_2_8_loss: 0.5569 - dense_2_9_loss: 0.9848 - dense_2_accuracy: 0.9995 - dense_2_1_accuracy: 0.9996 - dense_2_2_accuracy: 0.9405 - dense_2_3_accuracy: 0.9639 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9579 - dense_2_6_accuracy: 0.7890 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.7748 - dense_2_9_accuracy: 0.6049\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 2.3142 - dense_2_loss: 0.0078 - dense_2_1_loss: 0.0032 - dense_2_2_loss: 0.1427 - dense_2_3_loss: 0.1763 - dense_2_4_loss: 0.0032 - dense_2_5_loss: 0.1028 - dense_2_6_loss: 0.5440 - dense_2_7_loss: 0.0027 - dense_2_8_loss: 0.4727 - dense_2_9_loss: 0.8589 - dense_2_accuracy: 0.9996 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9462 - dense_2_3_accuracy: 0.9705 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9603 - dense_2_6_accuracy: 0.8074 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.8108 - dense_2_9_accuracy: 0.6509\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 2.0501 - dense_2_loss: 0.0070 - dense_2_1_loss: 0.0032 - dense_2_2_loss: 0.1285 - dense_2_3_loss: 0.1533 - dense_2_4_loss: 0.0027 - dense_2_5_loss: 0.0995 - dense_2_6_loss: 0.4949 - dense_2_7_loss: 0.0025 - dense_2_8_loss: 0.3979 - dense_2_9_loss: 0.7605 - dense_2_accuracy: 0.9995 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9535 - dense_2_3_accuracy: 0.9749 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9605 - dense_2_6_accuracy: 0.8283 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.8455 - dense_2_9_accuracy: 0.6844\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 4s 28ms/step - loss: 1.8137 - dense_2_loss: 0.0062 - dense_2_1_loss: 0.0027 - dense_2_2_loss: 0.1164 - dense_2_3_loss: 0.1334 - dense_2_4_loss: 0.0028 - dense_2_5_loss: 0.0933 - dense_2_6_loss: 0.4406 - dense_2_7_loss: 0.0024 - dense_2_8_loss: 0.3421 - dense_2_9_loss: 0.6738 - dense_2_accuracy: 0.9996 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9574 - dense_2_3_accuracy: 0.9813 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9627 - dense_2_6_accuracy: 0.8481 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.8681 - dense_2_9_accuracy: 0.7169\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e50040520>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePf2CDQb9gQ-"
      },
      "source": [
        "# Let's do some \"translation\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJdBoaJE9gRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4826096-52f1-4285-f20a-4d923de16485"
      },
      "source": [
        "def prep_input(input_list):\n",
        "    X = []\n",
        "    for line in input_list:\n",
        "        temp=[]\n",
        "        for char in line:\n",
        "            temp.append(char_to_ix[char])\n",
        "        X.append(temp)\n",
        "    X = pad_sequences(X,maxlen=maxlen)\n",
        "    X= to_categorical(X,vocab_size)\n",
        "    X=X.reshape(len(input_list),maxlen ,vocab_size)\n",
        "    \n",
        "    return X\n",
        "\n",
        "EXAMPLES = ['3 May 1999', '05 October 2009', '30 August 2016', '11 July 2000', 'Saturday 19 May 2018', '3 March 2001', '1 March 2001']\n",
        "s0 = np.zeros((len(EXAMPLES), n_s))\n",
        "c0 = np.zeros((len(EXAMPLES), n_s))\n",
        "EXAMPLES = prep_input(EXAMPLES)\n",
        "\n",
        "prediction = model.predict([EXAMPLES , s0, c0])\n",
        "prediction = np.swapaxes(prediction,0,1)\n",
        "prediction = np.argmax(prediction, axis = -1)\n",
        "\n",
        "for j in range(len(prediction)):\n",
        "    output = \"\".join([ix_to_output_char[int(i)] for i in prediction[j]])\n",
        "    print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "1999-05-23\n",
            "2009-10-06\n",
            "2016-08-33\n",
            "2000-07-11\n",
            "2018-05-19\n",
            "2001-03-33\n",
            "2001-03-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_um44CnrVCsp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}