{"cells":[{"cell_type":"markdown","metadata":{"id":"IRBubL3il3TB"},"source":[]},{"cell_type":"markdown","metadata":{"id":"7EdbVSmE87En"},"source":["# HW1: Dictionary-based Tokenization \n"]},{"cell_type":"markdown","metadata":{"id":"pJJLm1Ub87Et"},"source":["In this exercise, you are to implement a dictionary-based word segmentation algorithm. There are two Python functions that you need to complete: \n","<br>\n","* maximal_matching\n","* backtrack\n","</br>\n","\n","Also, you have to find how to use word_tokenize() in PythaiNLP along with customer_dict by yourselves."]},{"cell_type":"markdown","metadata":{"id":"DF5Pme7CK3YF"},"source":["## Part1) Your Maximal Matching with Your Dictionary"]},{"cell_type":"markdown","metadata":{"id":"xzs0R06q87Et"},"source":["### Create a toy dictionary to test the algorithm\n","\n","This is based on the example shown in the lecture. \n","You will tokenize the following text string: \"ไปหามเหสี!\"\n","The toy dictoionary provided in this exercise includes all the charaters, syllables, and words that appear that the text string."]},{"cell_type":"code","execution_count":83,"metadata":{"id":"pq3W4p3z87Ev"},"outputs":[],"source":["thai_vocab = [\"ไ\",\"ป\",\"ห\",\"า\",\"ม\",\"เ\",\"ห\",\"ส\",\"ี\",\"ไป\",\"หา\",\"หาม\",\"เห\",\"สี\",\"มเหสี\",\"!\"]"]},{"cell_type":"markdown","metadata":{"id":"ZornooGF87Ew"},"source":["### Maximal matching \n","Complete the maximal matching  function below to tokenize the input text\n"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"Ao4d2E3387Ew"},"outputs":[],"source":["# c is the character array\n","from math import inf #infinity\n","def maximal_matching(c):\n","    #Initialize an empty 2D list\n","    d =[[None]*len(c) for _ in range(len(c))]\n","    ####FILL CODE HERE####\n","    for i in range(len(c)):\n","        word = \"\"\n","        Num = 0\n","        if i>0:\n","            Min_of_word = list(map(lambda x: d[x][i-1] , range(i)))\n","            Num = min(Min_of_word)\n","        for k in range(i,len(c)):\n","            word+=c[k]\n","            if word in thai_vocab:\n","                d[i][k] = 1+Num\n","                print(word + \" type is : int and Num is\"+str(d[i][k]))\n","            else : \n","                # print(word + \" is type : inf\")\n","                d[i][k] = inf   \n","\n","\n","    ######################\n","    \n","    return d"]},{"cell_type":"markdown","metadata":{"id":"w7vBXfjM87Ew"},"source":["### Backtracking\n","Complete the backtracking function below to find the tokenzied words.\n","It should return a list containing a pair of the beginning position and the ending position of each word.\n","In this example, it should return: \n","<br>\n","[(0, 1),(2, 3),(4, 8),(9, 9)]\n","<br> \n","#### Each pair contains the position of each word as follows:\n","(0, 1) ไป\n","<br>\n","(2, 3) หา\n","<br>\n","(4, 8) มเหสี\n","<br>\n","(9, 9) !\n"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"SxNFf1IE87Ex"},"outputs":[],"source":["def backtrack(d):\n","    eow = len(d)-1 # End of Word position\n","    word_pos = [] # Word position\n","    ####FILL CODE HERE####\n","    i = 0\n","    k = 0\n","    while 1:\n","        i+=k\n","        if i >= len(d):\n","            word_pos+=[[min(word),max(word)]]\n","            break\n","        word = []\n","        \n","        Min_of_word = list(map(lambda x: d[x][eow-i] , range(eow-i,-1,-1)))\n","        Min_of_word.reverse()\n","        print(\"i is \"+str(i)+\" MoW is \"+str(Min_of_word))\n","        Num = min(Min_of_word)\n","        Min_of_index = Min_of_word.index(Num)\n","        k=0\n","        for j in range(eow-i,-1,-1):\n","            if type(d[Min_of_index][j]) == int or d[Min_of_index][j] == inf :\n","                word+=[j]\n","                k+=1\n","            else:\n","                word_pos+=[[min(word),max(word)]]\n","                # i+=1\n","                break\n","    ######################\n","    word_pos.reverse()\n","    return word_pos\n"]},{"cell_type":"markdown","metadata":{"id":"q0MJkKsh87Ex"},"source":["### Test your maximal matching algorithm on a toy dictionary\n","\n","Expected output:\n","\n","[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","<br>\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","<br>\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","<br>\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","<br>\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","<br>\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","<br>\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","<br>\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","<br>\n","[None, None, None, None, None, None, None, None, None, 4] !\n","<br>"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"tsmVQIKS87Ey"},"outputs":[{"name":"stdout","output_type":"stream","text":["ไ type is : int and Num is1\n","ไป type is : int and Num is1\n","ป type is : int and Num is2\n","ห type is : int and Num is2\n","หา type is : int and Num is2\n","หาม type is : int and Num is2\n","า type is : int and Num is3\n","ม type is : int and Num is3\n","มเหสี type is : int and Num is3\n","เ type is : int and Num is3\n","เห type is : int and Num is3\n","ห type is : int and Num is4\n","ส type is : int and Num is4\n","สี type is : int and Num is4\n","ี type is : int and Num is5\n","! type is : int and Num is4\n","[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","[None, None, None, None, None, None, None, None, None, 4] !\n"]}],"source":["input_text = \"ไปหามเหสี!\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"]},{"cell_type":"markdown","metadata":{"id":"IVhCMM4d87Ey"},"source":["### Test your backtracking algorithm on a toy dictionary\n","Expected output:\n","<br>\n","ไป|หา|มเหสี|!"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"6Hurbm1f87Ey"},"outputs":[{"name":"stdout","output_type":"stream","text":["i is 0 MoW is [inf, inf, inf, inf, inf, inf, inf, inf, inf, 4]\n","i is 1 MoW is [inf, inf, inf, inf, 3, inf, inf, 4, 5]\n","i is 6 MoW is [inf, inf, 2, 3]\n","i is 8 MoW is [1, 2]\n","ไป|หา|มเหสี|!\n"]}],"source":["def print_tokenized_text(d, input_text):\n","    tokenized_text=[]\n","    for pos in backtrack(d):\n","        # print(pos)\n","        # print(input_text[pos[0]:pos[1]+1])\n","        tokenized_text.append(input_text[pos[0]:pos[1]+1])\n","\n","    print(\"|\".join(tokenized_text))\n","    \n","print_tokenized_text(out,input_text)"]},{"cell_type":"markdown","metadata":{"id":"57rP9cTU87Ez"},"source":["## Part2) Your Maximal Matching with Real Dictionary"]},{"cell_type":"markdown","metadata":{"id":"V306h7AG87Ez"},"source":["For UNIX-based OS users, the following cell will download a dictionary (it's just a list of thai words). Alternatively, you can download it from this link: https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1675821102082,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"EFVR9LO187Ez","outputId":"1f38b1ec-8f67-4afe-d173-921993033fbf","scrolled":true},"outputs":[],"source":["# !wget https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1675821102084,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"nqIQzVgE87E0","outputId":"f38bc3d8-83b8-4485-8bc3-af1504b8fdbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocab size: 62069\n"]}],"source":["with open(\"words_th.txt\",encoding='utf-8-sig') as f:\n","    thai_vocab = f.read().splitlines() \n","print(\"Vocab size:\", len(thai_vocab))\n","thai_vocab.extend([\"ๆ\",\"!\"])"]},{"cell_type":"markdown","metadata":{"id":"Kpjwzw1w87E0"},"source":["### The output of your maximal matching algoithm on a new dictionary\n","Expected output:\n","<br>\n","[1, 1, 100000, 1, 100000, 100000, 100000, 100000, 100000] ไ\n","<br>\n","[None, 2, 100000, 100000, 100000, 100000, 100000, 100000, 100000] ป\n","<br>\n","[None, None, 2, 2, 2, 100000, 100000, 100000, 100000] ห\n","<br>\n","[None, None, None, 100000, 100000, 100000, 100000, 100000, 100000] า\n","<br>\n","[None, None, None, None, 2, 100000, 100000, 100000, 2] ม\n","<br>\n","[None, None, None, None, None, 100000, 3, 100000, 100000] เ\n","<br>\n","[None, None, None, None, None, None, 100001, 100000, 100000] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4] ส\n","<br>\n","[None, None, None, None, None, None, None, None, None] ี"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"lYD5ChIS87E0"},"outputs":[{"name":"stdout","output_type":"stream","text":["ไป type is : int and Num is1\n","ไปหา type is : int and Num is1\n","หา type is : int and Num is2\n","หาม type is : int and Num is2\n","มเหสี type is : int and Num is2\n","เห type is : int and Num is3\n","สี type is : int and Num is4\n"]}],"source":["input_text = \"ไปหามเหสี\"\n","out = maximal_matching(input_text)\n","# for i in range(len(out)):\n","#     print(out[i],input_text[i])"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[inf, 1, inf, 1, inf, inf, inf, inf, inf] ไ\n","[None, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, inf, 2, 2, inf, inf, inf, inf] ห\n","[None, None, None, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, inf, inf, inf, inf, 2] ม\n","[None, None, None, None, None, inf, 3, inf, inf] เ\n","[None, None, None, None, None, None, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, inf, 4] ส\n","[None, None, None, None, None, None, None, None, inf] ี\n"]}],"source":["for i in range(len(out)):\n","    print(out[i],input_text[i])"]},{"cell_type":"markdown","metadata":{"id":"BSqLuK7G87E0"},"source":["### Expected tokenized text\n","ไปหา|มเหสี"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"TI077jmy87E0"},"outputs":[{"name":"stdout","output_type":"stream","text":["i is 0 MoW is [inf, inf, inf, inf, 2, inf, inf, 4, inf]\n","i is 5 MoW is [1, inf, 2, inf]\n","ไปหา|มเหสี\n"]}],"source":["print_tokenized_text(out,input_text)"]},{"cell_type":"markdown","metadata":{"id":"VLGgO8PrLSz6"},"source":["## Part3) Maximal Matching from PythaiNLP"]},{"cell_type":"markdown","metadata":{"id":"LrZrzQoXLeUX"},"source":["### Default dictionary\n","\n","Study word_tokenize() from PythaiNLP in the link below.\n","\n","https://thainlp.org/pythainlp/docs/2.0/api/tokenize.html"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"yXxPBOcNLXfm"},"outputs":[],"source":["# %pip install wheel\n","# %pip install pythainlp\n","# %pip install marisa_trie\n","# %pip install --upgrade --pre pythainlp"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"goQE5gFUL4KO"},"outputs":[{"name":"stdout","output_type":"stream","text":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่าน', 'มิตร', 'ทาวน์']\n","['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็ได้', 'ที่สาม', 'ย่าน', 'มิตร', 'ทาวน์']\n"]}],"source":["from pythainlp.tokenize import word_tokenize\n","text='นัดกินกันตอนไหนก็ได้ที่สามย่านมิตรทาวน์'\n","\n","####FILL CODE HERE####\n","print(word_tokenize(text,engine=\"newmm\"))\n","print(word_tokenize(text,engine=\"longest\"))\n","\n","######################"]},{"cell_type":"markdown","metadata":{"id":"2SlX5cEBMHPd"},"source":["### Custom dictionary\n","\n","Add 'สามย่านมิตรทาวน์' into dictionary and then tokenize again"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"b4V9TqFaMPAj"},"outputs":[{"name":"stdout","output_type":"stream","text":["['นัดกินกันตอนไหนก็ได้ที่', 'สามย่านมิตรทาวน์']\n","['นัดกิน', 'กันตอน', 'ไหนก็ได้ที่สามย่านมิตรทาวน์']\n"]}],"source":["####FILL CODE HERE####\n","import marisa_trie\n","custom_dict = marisa_trie.Trie(['สามย่านมิตรทาวน์'])\n","print(word_tokenize(text,custom_dict=custom_dict,engine='newmm'))\n","custom_dict = marisa_trie.Trie(['นัดกิน','กันตอน'])\n","print(word_tokenize(text,custom_dict=custom_dict,engine='newmm'))\n","######################"]}],"metadata":{"colab":{"collapsed_sections":["DF5Pme7CK3YF","xzs0R06q87Et","ZornooGF87Ew","w7vBXfjM87Ew","q0MJkKsh87Ex","57rP9cTU87Ez","Kpjwzw1w87E0","BSqLuK7G87E0","VLGgO8PrLSz6","LrZrzQoXLeUX","2SlX5cEBMHPd"],"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"}}},"nbformat":4,"nbformat_minor":0}
